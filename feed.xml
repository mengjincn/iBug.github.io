<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://ibugone.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ibugone.com/" rel="alternate" type="text/html" /><updated>2020-02-16T10:24:21+00:00</updated><id>https://ibugone.com/feed.xml</id><title type="html">iBug One</title><subtitle>The little personal site for iBug</subtitle><author><name>iBug</name></author><entry><title type="html">3 ways to use MySQL / MariaDB CLI without password</title><link href="https://ibugone.com/blog/2020/02/use-mysql-cli-without-password/" rel="alternate" type="text/html" title="3 ways to use MySQL / MariaDB CLI without password" /><published>2020-02-04T00:00:00+00:00</published><updated>2020-02-11T12:41:43+00:00</updated><id>https://ibugone.com/blog/2020/02/use-mysql-cli-without-password</id><content type="html" xml:base="https://ibugone.com/blog/2020/02/use-mysql-cli-without-password/">&lt;p&gt;For all of us who are learning to use or developing with MySQL or MariaDB, it’s a common task to manually log in to the database for inspection. This is usually done with the &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; command line client, and for sure it’s cumbersome to log in to the database using your application’s credentials. For convenience purposes, you would like to make your life easy by configuring the &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; CLI to &lt;strong&gt;NOT&lt;/strong&gt; prompt you for a password each time. Here are three ways to do it on Linux.&lt;/p&gt;
				&lt;p&gt;(This may work on BSD and macOS as well, but I haven’t tested.)&lt;/p&gt;
				&lt;h2 id=&quot;method-1-use-sudo&quot;&gt;Method 1: Use &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt;&lt;/h2&gt;
				&lt;p&gt;By default, the local root user can log in to MySQL or MariaDB without password, so you can just use &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo mysql&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt;, and expect everything to work. Of course, this depends on your &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt; to not ask you for a password, or you’ll still have to enter one for the root privilege.&lt;/p&gt;
				&lt;p&gt;You can go one step further by adding &lt;code class=&quot;highlighter-rouge&quot;&gt;alias mysql='sudo mysql'&lt;/code&gt; to your &lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt; or whatever shell you’re using, but this is still a bit hackish, and IMO is more a workaround than a solution, so read on before proceeding.&lt;/p&gt;
				&lt;h2 id=&quot;method-2-use-a-password-and-remember-it-somewhere&quot;&gt;Method 2: Use a password and remember it somewhere&lt;/h2&gt;
				&lt;p&gt;The second option is to use a password, and let it be “automatically supplied” in some other way.&lt;/p&gt;
				&lt;p&gt;First, create a database user for yourself. Don’t forget to replace &lt;code class=&quot;highlighter-rouge&quot;&gt;ibug&lt;/code&gt; with your username.&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'some_password'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;FLUSH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Now you can log in to MySQL or MariaDB using &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql -uibug -p'some password'&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;You’re probably urged to add that as an alias in your &lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt;, but hold on again, that’s the wrong way to do it. In case your &lt;code class=&quot;highlighter-rouge&quot;&gt;.bashrc&lt;/code&gt; is readable by others, you risk exposing your password. Also, in case you want to log in as another user some time later, you may mess things up because of the alias expansion.&lt;/p&gt;
				&lt;p&gt;The correct way to store the password for yourself is to write it in a file named &lt;code class=&quot;highlighter-rouge&quot;&gt;.my.cnf&lt;/code&gt; under your home directory. Its content should look like this:&lt;/p&gt;
				&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;[client]&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ibug&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;password&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;some_password&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Remember to &lt;code class=&quot;highlighter-rouge&quot;&gt;chmod 600&lt;/code&gt; on it so no one else reads it. You can now try running &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; directly, and it’ll read your username and password from &lt;code class=&quot;highlighter-rouge&quot;&gt;.my.cnf&lt;/code&gt; without prompting you for anything.&lt;/p&gt;
				&lt;p&gt;But again, if you use a weak password and someone manages to guess it, you still risk exposing your whole MySQL database to them.&lt;/p&gt;
				&lt;p&gt;Think how the root user on your system logs in to MySQL directly - it’s safe and secure, because you can’t log in without password using the root user (unless you’re running &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; as root, but not &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql -uroot -p&lt;/code&gt; as a regular user). The good news is, &lt;em&gt;you&lt;/em&gt; can replicate this setup for yourself! So read on for the last and perfect solution.&lt;/p&gt;
				&lt;h2 id=&quot;method-3-use-unix-authentication&quot;&gt;Method 3: Use Unix authentication&lt;/h2&gt;
				&lt;p&gt;A bit of background first. Like how one can get the address and port of other end of a TCP or UDP socket, one can also get the connector information of the other end of a unix socket, namely, the process ID, user ID and group ID (see &lt;a href=&quot;http://man7.org/linux/man-pages/man7/unix.7.html&quot; title=&quot;unix(7)&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;man 7 unix&lt;/code&gt;&lt;/a&gt;, look for &lt;code class=&quot;highlighter-rouge&quot;&gt;SCM_CREDENTIALS&lt;/code&gt;).&lt;/p&gt;
				&lt;p&gt;When you run &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; on your local machine, it will try to connect to the MySQL server using a unix socket located at &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/run/mysqld/mysqld.sock&lt;/code&gt;, and this way the MySQL server will know who it is trying to connect. This is exactly how MySQL identifies the local root user: The root user won’t have the same access if it tries connecting via TCP (i.e. &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql -h 127.0.0.1&lt;/code&gt;).&lt;/p&gt;
				&lt;p&gt;To let MySQL recognize you using unix socket magic, you can use the following query to create your user:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;If you have already created a user, you can change its authentication method by simply replacing &lt;code class=&quot;highlighter-rouge&quot;&gt;CREATE&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;ALTER&lt;/code&gt; in the above query:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;ALTER&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;auth_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;div class=&quot;notice--primary&quot;&gt;
				&lt;h3 id=&quot;mariadb-makes-a-difference-here&quot;&gt;&lt;i class=&quot;fas fa-exclamation-circle&quot;&gt;&lt;/i&gt; MariaDB makes a difference here!&lt;/h3&gt;
				&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/MariaDB&quot;&gt;MariaDB&lt;/a&gt;, a community fork of Oracle MySQL, uses a similar query for unix socket authentication:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;CREATE&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;USER&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VIA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unix_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;c1&quot;&gt;--                                        ^^^^^^^^^^^^^^^&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
				&lt;p&gt;Better yet, MariaDB supports user creation with &lt;code class=&quot;highlighter-rouge&quot;&gt;GRANT&lt;/code&gt; query, so the first two queries can be merged into one:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VIA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unix_socket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
				&lt;/div&gt;
				&lt;p&gt;After the user is set up properly, use the same &lt;code class=&quot;highlighter-rouge&quot;&gt;GRANT&lt;/code&gt; query to grant access to yourself.&lt;/p&gt;
				&lt;p&gt;Now you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; to manage your whole database without being prompted for password. You can safely delete &lt;code class=&quot;highlighter-rouge&quot;&gt;.my.cnf&lt;/code&gt; if you created it following Method 2 and you don’t have other options in it. You can also try using &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql -u&amp;lt;your username&amp;gt;&lt;/code&gt; under another user and see it fail, to ensure that only &lt;em&gt;you&lt;/em&gt; can access the database directly.&lt;/p&gt;
				&lt;h2 id=&quot;-creating-and-granting-access-to-more-users&quot;&gt;&lt;i class=&quot;fas fa-lightbulb&quot;&gt;&lt;/i&gt; Creating and granting access to more users&lt;/h2&gt;
				&lt;p&gt;If you want to create more users with your &lt;code class=&quot;highlighter-rouge&quot;&gt;mysql&lt;/code&gt; command line, you’ll probably see this message:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ERROR 1045 (28000): Access denied for user 'ibug'@'localhost' (using password: YES)
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;This is because you haven’t granted yourself &lt;em&gt;the privilege to grant&lt;/em&gt;, or in other words, your privilege isn’t “redistributable”.&lt;/p&gt;
				&lt;p&gt;You can set the privileges again, but with the privilege to “redistribute” your access to more users, with the following query:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OPTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;FLUSH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Similarly, the one-liner for MariaDB looks like this:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ALL&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;ON&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;TO&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ibug'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'localhost'&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IDENTIFIED&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;VIA&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unix_socket&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;WITH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;GRANT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;OPTION&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;FLUSH&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;PRIVILEGES&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Both MySQL and MariaDB requires “flushing” after any privilege assignment is altered.&lt;/p&gt;
				&lt;p&gt;You can then create more users with your passwordless access, and play around with MySQL to fulfill your curiosity.&lt;/p&gt;
				&lt;p&gt;And that concludes this tutorial. Cheers!&lt;/p&gt;</content><author><name>iBug</name></author><category term="linux" /><category term="mysql" /><summary type="html">For all of us who are learning to use or developing with MySQL or MariaDB, it’s a common task to manually log in to the database for inspection. This is usually done with the mysql command line client, and for sure it’s cumbersome to log in to the database using your application’s credentials. For convenience purposes, you would like to make your life easy by configuring the mysql CLI to NOT prompt you for a password each time. Here are three ways to do it on Linux.</summary></entry><entry><title type="html">High-performance mass web crawling on AWS</title><link href="https://ibugone.com/blog/2019/12/mass-crawl-douban-with-aws/" rel="alternate" type="text/html" title="High-performance mass web crawling on AWS" /><published>2019-12-28T00:00:00+00:00</published><updated>2020-01-04T02:56:29+00:00</updated><id>https://ibugone.com/blog/2019/12/mass-crawl-douban-with-aws</id><content type="html" xml:base="https://ibugone.com/blog/2019/12/mass-crawl-douban-with-aws/">&lt;p&gt;The 3rd-and-last experiment of course &lt;em&gt;Web Information Processing and Application&lt;/em&gt; required us to create a recommendation engine, and “predict” the rating (1-5 stars) for 4M user-item pairs based on the training data of 9M user-item pairs and a social network.&lt;/p&gt;
				&lt;p&gt;The interesting part is, all user and rating data are real, i.e. unmasked. This makes it possible to, instead of playing nicely by doing data analysis, crawl the target data directly, bypassing the aim of the experiment to learn about recommendation systems, which is exactly the way I chose and I’m going to describe in this article.&lt;/p&gt;
				&lt;p&gt;To make things challenging, the target website, &lt;a href=&quot;https://www.douban.com/&quot;&gt;Douban&lt;/a&gt;, has a moderate level of anti-spider techniques in place. This makes it impossible to just submit a truckload of requests hoping to retrieve all data desired, but more advanced technologies and cleverer tactics are mandatory before pulling it off.&lt;/p&gt;
				&lt;h2 id=&quot;part-1&quot;&gt;Part 1: Scrapy and ScrapingHub&lt;/h2&gt;
				&lt;p&gt;Previously I’ve done crawlers using &lt;a href=&quot;https://2.python-requests.org/&quot;&gt;requests&lt;/a&gt; + &lt;a href=&quot;https://www.crummy.com/software/BeautifulSoup/&quot;&gt;Beautiful Soup&lt;/a&gt;, but this time under suggestions from my roommate, I decided to try it out with &lt;a href=&quot;https://scrapy.org/&quot;&gt;Scrapy&lt;/a&gt;, a said-to-be-great web crawling framework.&lt;/p&gt;
				&lt;p&gt;Scrapy is a framework extremely easy to start with. I followed the guide on Scrapy’s website and wrote less than 30 lines of Python (&lt;a href=&quot;https://github.com/iBug/douban-spider/commit/8aead82&quot;&gt;commit&lt;/a&gt;), and the first version of my spider was ready to go.&lt;/p&gt;
				&lt;p&gt;It didn’t take too long before I picked up on Douban’s anti-spider techniques. My server’s IP was banned (fortunately, only temporarily) and all requests to Douban were getting 403 responses.&lt;/p&gt;
				&lt;p&gt;I fortuitously recalled that GitHub Student Pack provides an offer from &lt;a href=&quot;https://scrapinghub.com/&quot;&gt;ScrapingHub&lt;/a&gt;, the company behind Scrapy, containing one scraper unit, for free forever. Following their guide on deployment, I asked my teammate to modify my spider to adopt Scrapy’s project layout (&lt;a href=&quot;https://github.com/iBug/douban-spider/compare/cecbcfb..8eb1ff1&quot;&gt;commit&lt;/a&gt;), redeemed the Student Pack offer, and deployed my first scraper project onto ScrapingHub cloud.&lt;/p&gt;
				&lt;figure&gt;
				&lt;img src=&quot;/image/scrapinghub.png&quot; alt=&quot;ScrapingHub results&quot; /&gt;
				&lt;figcaption&gt;
				My job history on ScrapingHub, all of which are for this experiment
				&lt;/figcaption&gt;
				&lt;/figure&gt;
				&lt;p&gt;ScrapingHub has forced AutoThrottle enabled for all jobs, so my first SH job survived for longer before it started receiving 403 responses. Looking at the stats, the job maintained its position for about 40 minutes, before signals of having its IP banned emerged. I updated the scraper a few times to include detections for more variations of indications of an IP ban, but never made it over an hour. And because I only attempted to avoid the IP ban by throttling and detecting, the actual “targets” contained in the code remained the same, which accounted for high duplication in crawled results in the first few runs, which in turn led to a quick drop in the increase of the submitted result (of this course experiment).&lt;/p&gt;
				&lt;p&gt;Recalling that I had spare promotional credits from AWS Educate, I came up with the idea of utilizing the large IP pool of AWS, which has another advantage of the ease to swap out a banned one.&lt;/p&gt;
				&lt;h2 id=&quot;part-2&quot;&gt;Part 2: Expansion onto AWS, distributed crawling with centralized management&lt;/h2&gt;
				&lt;p&gt;The high duplication rate of results from the first few runs on ScrapingHub was alarming: I knew that I wouldn’t make any real success if I didn’t build a centralized job dispatcher and data collector, so the first thing before moving onto AWS is to create a control center.&lt;/p&gt;
				&lt;h3 id=&quot;central-management&quot;&gt;The central manager server&lt;/h3&gt;
				&lt;p&gt;I picked my favorite quickstarter framework Flask, implemented three simple interfaces &lt;code class=&quot;highlighter-rouge&quot;&gt;get job&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;update job&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;add result&lt;/code&gt;. To make things absolutely simple yet reliable, I picked SQLite as database backend because it’s easy to setup and query (&lt;code class=&quot;highlighter-rouge&quot;&gt;sqlite3&lt;/code&gt; CLI is ready for use). I designed a “job pool” with push-pop architecture, where each job record is a to-be-crawled URL, and is deleted from the pool once it’s requested. The spider then crawls the page, send results back to the control center, as well as the “Next Page” link in the page back into the job pool if there is one. It didn’t even take a lot of effort to work this out (&lt;a href=&quot;https://github.com/iBug/douban-spider/blob/5da2c80/server.py&quot;&gt;code&lt;/a&gt;). The initial content in the “job pool” is Page 1 of all 20000 users, imported from experiment materials manually. A user is considered “done” if one of the pages in the chain doesn’t contain a “Next Page” link, meaning that the last page for this user has been reached.&lt;/p&gt;
				&lt;p&gt;Deployment is just as easy. I wrapped the server up in a Docker container, put it on my primary server on Amazon Lightsail (2 GB instance, has some other stuff running already), configured Nginx and added a DNS record on Cloudflare. Then I started the spider on my workstation and send a few initial requests, to test if everything proceeds as expected. After cleaning a few obvious bugs out of the code base, I started configuring a spider client.&lt;/p&gt;
				&lt;h3 id=&quot;distributed-crawlers&quot;&gt;Distributed crawler clients&lt;/h3&gt;
				&lt;p&gt;Because I planned to spawn a large amount of clients, I want to lower their cost (I have only $100 credits and can’t spend overbudget), so I started off with t3.nano instances as they offered twice the CPU power and slightly less expense over the previous-generation t2.nano. Configuring the environment wasn’t any difficult, as all that was needed was a deploy key and dependency packages. The former can be generated locally and have the public part uploaded to GitHub before copying the private part onto the spider server, and the latter is as easy as running &lt;code class=&quot;highlighter-rouge&quot;&gt;pip install&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;To make further deployment easier, I created a systemd service for the spider job, and added &lt;code class=&quot;highlighter-rouge&quot;&gt;git pull&lt;/code&gt; before starting, so I only need to restart all servers and they’d pull in latest changes automatically. This is the service file that I wrote for this job.&lt;/p&gt;
				&lt;div class=&quot;language-ini highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nn&quot;&gt;[Unit]&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Douban Spider&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;After&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;multi-user.target&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;StartLimitIntervalSec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;0&lt;/span&gt;
				&lt;span class=&quot;nn&quot;&gt;[Service]&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;Type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;simple&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;Restart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;always&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;RestartSec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;ExecStartPre&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/usr/bin/git -C /root/douban-spider pull&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;ExecStart&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/usr/local/bin/scrapy crawl doubanspider&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;WorkingDirectory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/root/douban-spider/&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;TimeoutSec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5&lt;/span&gt;
				&lt;span class=&quot;nn&quot;&gt;[Install]&lt;/span&gt;
				&lt;span class=&quot;py&quot;&gt;WantedBy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;multi-user.target&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;I ran &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl daemon-reload&lt;/code&gt; to let systemd reload and be aware of my new service unit. I then started the spider with &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl start spider.service&lt;/code&gt; and followed &lt;code class=&quot;highlighter-rouge&quot;&gt;journalctl -ef&lt;/code&gt; to check if the spider is running properly. To make the spider start automatically on boot, I ran &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl enable spider.service&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;As I was going to work around Douban’s IP limitations, I let the spider shut down itself when it discovers the IP ban (&lt;a href=&quot;https://github.com/iBug/douban-spider/commit/d4b7e20&quot;&gt;commit&lt;/a&gt;). This way by looking at the number of running instances on EC2 dashboard, I can determine how many IPs have been banned, and can get new IPs by starting them up again (rebooting doesn’t change instance IP, must stop completely and then start again).&lt;/p&gt;
				&lt;p&gt;I then rebooted the server once, and checked again to be 100% sure that everything is working as expected. Confirming that, I shut down the server and took a snapshot of it.&lt;/p&gt;
				&lt;figure&gt;
				&lt;img src=&quot;/image/spider-aws/snapshot.png&quot; alt=&quot;Snapshot of a spider instance&quot; /&gt;
				&lt;figcaption&gt;
				Information panel of a snapshot taken from a properly configured spider instance, ready for deployment
				&lt;/figcaption&gt;
				&lt;/figure&gt;
				&lt;p&gt;And as well, before launching new instances from this snapshot, an AMI (Amazon Machine Image) has to be registered based off of it, so I did one as well.&lt;/p&gt;
				&lt;figure&gt;
				&lt;img src=&quot;/image/spider-aws/ami.png&quot; alt=&quot;AMI registered from the above snapshot&quot; /&gt;
				&lt;figcaption&gt;
				Information panel of an Amazon Machine Image registered from the above snapshot
				&lt;/figcaption&gt;
				&lt;/figure&gt;
				&lt;p&gt;I Googled about AWS service limits, and acknowledged that there was a “20 instances per region” limit on EC2. So I attempted to create 20 t3.nano instances from the AMI, but was informed that the launch request would fail for exceeding another resource limit of 32 vCPUs. OK, that was fine, I decided to launch 12 instance first, and launch the remaining 8 with one vCPU disabled, resulting in a total of 32 vCPUs. Unfortunately it failed again for unknown reasons, though I managed to figure it out that disabled vCPUs still count, so I ended up creating t2.nano instances for the rest of them.&lt;/p&gt;
				&lt;p&gt;It wasn’t necessarily something bad, however, as T2 series of instances can burst to 100% CPU for 30 minutes after startup, which should cover most of its lifetime before it gets banned.&lt;/p&gt;
				&lt;div class=&quot;notice&quot;&gt;
				&lt;p&gt;I have forgotten how I realized this, but the current actuality is that there’s no more “instance limit”, but only a limit on total vCPU count. This is still effectively a limit on the number of instances you can have simultaneously, though you get to keep less if you run multi-core instances.&lt;/p&gt;
				&lt;/div&gt;
				&lt;p&gt;My final setup was 32 t2.nano instances per region so as to maximize concurrency with maximum number of IPs available at once, while keeping cost low.&lt;/p&gt;
				&lt;h3 id=&quot;part-2-results&quot;&gt;Results&lt;/h3&gt;
				&lt;p&gt;As soon as I booted up my first batch of 32 t2.nano instances, I noticed an unexpected situation: The manager server is running at constant 100% CPU load. Because Lightsail instances are backed by EC2 T2 series, I knew it wouldn’t sustain for long before having its CPU throttled due to insufficient CPU credits. So I cut off two spider clients, and launched an m5.large instance for the control center.&lt;/p&gt;
				&lt;p&gt;Things went on smoothly for a while, and before the job pool depleted, I could gather 500k to 600k results (up to 30 per page). I re-created the pool from scratch a few times, shuffled it each time, and restarted the whole spider swarm. Every time I “refreshed” the database, I could gather another 500k to 600k results, and things went strange in the same mysterious way. The problem was, I estimated that there’d be a total of 30M results, so 500k to 600k was really a small portion.&lt;/p&gt;
				&lt;p&gt;It’s still delighting that the crawled data from the first few attempts improved the RMSE of our submission from 1.341 to 1.308, though the urgency of a revolutionary refresh also emerged.&lt;/p&gt;
				&lt;h2 id=&quot;part-3&quot;&gt;Part 3: Redesigned management architecture, fine-grained control, more robust and faster&lt;/h2&gt;
				&lt;p&gt;The first version of the spider swarm was successful to an extent, but a highly-managed framework was cumbersome to further enhancements. I decided to identify the limitations and look for alternatives.&lt;/p&gt;
				&lt;h3 id=&quot;limitations&quot;&gt;Limitations of the previous-generation spider swarm&lt;/h3&gt;
				&lt;ul&gt;
				&lt;li&gt;The first thing to emphasize is that Scrapy is too powerful and comprehensive to be flexible. I only want to make requests and get results as rapidly as possible.
				&lt;ul&gt;
				&lt;li&gt;Scrapy manages almost everything for you, including concurrency control and speed limiting, which is pretty much unwanted when I need to have fine-grained control over them.&lt;/li&gt;
				&lt;/ul&gt;
				&lt;/li&gt;
				&lt;li&gt;Pool management was poor. “Jobs” can get lost if they aren’t sent back (pushed back) to the control center. This is most likely the primary cause for the quick depletion of the job pool after gathering ~500k results. (There was indeed a serious bug in the spider client, which I’ll talk about later on)&lt;/li&gt;
				&lt;li&gt;Unacceptably high CPU usage from the server application, which needs a serious reform as well. Looking at the screen of &lt;code class=&quot;highlighter-rouge&quot;&gt;htop&lt;/code&gt;, I guess that a large portion of the usage is made by SQLite queries, as I was doing a high concurrency server application with millions of rows in the database. SQLite doesn’t suit this kind of workload, really.&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;These barriers ought to be overcome one by one, so I started this revolution from the spider client.&lt;/p&gt;
				&lt;h3 id=&quot;new-spider-architecture&quot;&gt;Ditching Scrapy and reverting to requests + BeautifulSoup4&lt;/h3&gt;
				&lt;p&gt;Scrapy is an all-in-one comprehensive framework. You focus on extracting data from the fetched page, and Scrapy handles everything else for you. Unfortunately, this is a huge barrier for whoever wants to tune it in every aspect. It even handles 302 redirects, which takes quite some effort to disable. This is why I switched back to my original approach using requests to fetch content, and parse it with BeautifulSoup4. Paired with Python’s stock multithreading library, this new client easily achieved twice the speed of that of Scrapy. It’s surely possible to dig into Scrapy and tune it, but why waste that time and effort when it can be easily solved by switching away?&lt;/p&gt;
				&lt;p&gt;Previously when using Scrapy, I had to override its &lt;code class=&quot;highlighter-rouge&quot;&gt;start_requests&lt;/code&gt; method to fetch jobs from the server, and because Scrapy handles concurrency, I could not control how frequently a client fetches jobs, which was, to be honest, messy. With requests and &lt;code class=&quot;highlighter-rouge&quot;&gt;threading&lt;/code&gt;, I have full control over concurrency, and I can reliably decide or predict how many jobs should be fetched by a client before it “exhausts”.&lt;/p&gt;
				&lt;h3 id=&quot;new-server-architecture&quot;&gt;Pre-computed job pool and MySQL&lt;/h3&gt;
				&lt;p&gt;Another problem of the previous generation of my spider swarm was that rapid draining of the job pool always occurred too soon (after fetching ~500k records). This was actually a bug.&lt;/p&gt;
				&lt;h4 id=&quot;unexpected-response&quot;&gt;One bad bug led to the failure of the previous swarm&lt;/h4&gt;
				&lt;p&gt;In my first few “durability tests”, I discovered that Douban would send either a 403 or a 302 response when it detects unusual traffic. The former was easy to detect, but with Scrapy, 302 redirects are handled automatically, and I spent more than half an hour Googling just to disable this behavior. With &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt;, this is as simple as supplying &lt;code class=&quot;highlighter-rouge&quot;&gt;allow_redirect=False&lt;/code&gt; to the request method, which then enables the simplicity of checking the status code of the response.&lt;/p&gt;
				&lt;p&gt;The true failure was, Douban actually sends 200 responses occasionally, with the HTML body containing a single line of JavaScript that redirects to another page, with the browser’s information supplied. I didn’t realize this until I noticed that this second-generation swarm gradually stopped working completely, and SSH-ed into one of the spider servers, and checked the program log. Because I treated 200 responses as success, the spiders would only find that there was no data items and “Next Page” links in the returned page, and thinking that this “page chain” had been completed.&lt;/p&gt;
				&lt;h4 id=&quot;new-job-pool&quot;&gt;Pre-computed job pool&lt;/h4&gt;
				&lt;p&gt;Detecting this “new” kind of unwanted response was not hard, but it must be done. But the good thing is, I ditched the “pop-push” job pool design as well. This time I first ran a small bunch of spiders to crawl the Page 1 for all 20000 Douban users, extracted the total number of items from those pages, and computed the number of pages for each user, storing them into the database as the new job pool. No more jobs would be removed from the database, only marked as completed. This way I could easily discover failed jobs and re-enable them by flipping the “completed” flag manually by editing the database.&lt;/p&gt;
				&lt;h4 id=&quot;switching-to-mysql&quot;&gt;An RDBMS that scales&lt;/h4&gt;
				&lt;p&gt;The 1st-gen control center used SQLite as its database engine. SQLite is a lightweight, easy-to-start database. The problem is, it’s a single-file DB engine, and &lt;strong&gt;doesn’t scale&lt;/strong&gt;. I had millions of rows in the results table, and a large portion of responses when I try to query it using the &lt;code class=&quot;highlighter-rouge&quot;&gt;sqlite3&lt;/code&gt; CLI utility (for analysis purposes) are “&lt;em&gt;Error: database is locked&lt;/em&gt;”. The database also grows terribly, at more than 400 MB in size. Due to being constantly written to, I could even hardly make a copy of it without corruption. I had to do a &lt;code class=&quot;highlighter-rouge&quot;&gt;cp&lt;/code&gt; command for 10 times before I could have an intact copy of the database for copying back to my computer for future analysis.&lt;/p&gt;
				&lt;p&gt;SQLite isn’t the right tool for millions of records, really.&lt;/p&gt;
				&lt;p&gt;MySQL is a better database engine that’s widely used in production, and I have some experiences with it, so it became an apparent option to switch to it. As Debian provides MariaDB as the replacement for MySQL, installation was straightforward. I the modified the code to adopt the new database.&lt;/p&gt;
				&lt;p&gt;A few points to note:&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;Debian and its derivatives (including Ubuntu) uses the PyPI package &lt;a href=&quot;https://pypi.org/project/mysqlclient/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;mysqlclient&lt;/code&gt;&lt;/a&gt; to provide the package &lt;code class=&quot;highlighter-rouge&quot;&gt;python3-mysqldb&lt;/code&gt;. It’s compatible with the now-abandoned &lt;code class=&quot;highlighter-rouge&quot;&gt;MySQLdb&lt;/code&gt; package. Any code written for &lt;code class=&quot;highlighter-rouge&quot;&gt;MySQLdb&lt;/code&gt; should remain unchanged, because even the import line remains as &lt;code class=&quot;highlighter-rouge&quot;&gt;import MySQLdb&lt;/code&gt; instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;import mysqlclient&lt;/code&gt; (the latter will throw an &lt;code class=&quot;highlighter-rouge&quot;&gt;ImportError&lt;/code&gt; for not finding the module).&lt;/li&gt;
				&lt;li&gt;The MySQL uses a connection-cursor architecture, so instead of calling &lt;code class=&quot;highlighter-rouge&quot;&gt;db.execute&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;db.fetch*&lt;/code&gt; methods directly (as is the case with Python’s stock SQLite library), a cursor must be created first, and then &lt;code class=&quot;highlighter-rouge&quot;&gt;cursor.execute&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;cursor.fetch*&lt;/code&gt; methods will be available. Similarly, cursors need separate closing than the DB connection itself.&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;The painful thing is that SQLite uses the question mark &lt;code class=&quot;highlighter-rouge&quot;&gt;?&lt;/code&gt; as placeholder for query data (&lt;a href=&quot;https://xkcd.com/327/&quot;&gt;NEVER join database queries&lt;/a&gt;), while MySQL uses &lt;code class=&quot;highlighter-rouge&quot;&gt;%s&lt;/code&gt;. Compare the following code:&lt;/p&gt;
				&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;SQLite&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;MySQL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;INSERT&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;INTO&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;records&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;user&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rating&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;VALUES&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
				&lt;p&gt;It was somewhat frustrating to hunt for all those question marks and replacing them with &lt;code class=&quot;highlighter-rouge&quot;&gt;%s&lt;/code&gt;’s when you can’t use text-based find-and-replace. Still, though, I managed to get this work done.&lt;/p&gt;
				&lt;/li&gt;
				&lt;/ul&gt;
				&lt;h3 id=&quot;refresh-ip&quot;&gt;Continuous refresh of banned IPs&lt;/h3&gt;
				&lt;p&gt;As this time I made some changes to increase the aggregate crawl speed, it could be anticipated that IPs would be banned sooner than in the first generation, which rendered IP refreshing more important. I had already known that AWS provided an extensive REST API, as well as a powerful CLI utility &lt;code class=&quot;highlighter-rouge&quot;&gt;aws&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;I didn’t even need to install the &lt;code class=&quot;highlighter-rouge&quot;&gt;aws&lt;/code&gt; CLI utility because it comes preinstalled on every AMI, so all that was needed was to create an IAM user and generate API credentials following the &lt;a href=&quot;https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html&quot;&gt;AWS official documentation&lt;/a&gt;.&lt;/p&gt;
				&lt;p&gt;After figuring out all functionalities that I needed, I created a “runner script” that does everything automatically.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in
				&lt;/span&gt;1&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;REGION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ap-northeast-1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				2&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;REGION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ap-southeast-1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				3&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;REGION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'us-west-2'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				4&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;REGION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'us-west-1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;esac&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;case&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$2&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in
				&lt;/span&gt;1&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ACTION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'stop-instances'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				2&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;ACTION&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'start-instances'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1&lt;span class=&quot;p&quot;&gt;;;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;esac&lt;/span&gt;
				&lt;span class=&quot;nv&quot;&gt;INSTANCES&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;$(&lt;/span&gt;aws &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; text &lt;span class=&quot;nt&quot;&gt;--region&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$REGION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; ec2 describe-instances &lt;span class=&quot;nt&quot;&gt;--filters&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Name=instance-type,Values=t2.nano&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--query&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Reservations[].Instances[].InstanceId&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;tr&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'[:space:]'&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
				&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Instances: &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$INSTANCES&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-qiP&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'i-0[0-9a-f]+'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$INSTANCES&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
				&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Running &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ACTION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt; on &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$REGION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
				aws &lt;span class=&quot;nt&quot;&gt;--output&lt;/span&gt; json &lt;span class=&quot;nt&quot;&gt;--region&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$REGION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; ec2 &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$ACTION&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--instance-ids&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$INSTANCES&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;fi&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;The above script will attempt to list all spider instances (all of them are t2.nano), and depending on arguments, try to stop them and start them back up so they have new IPs to start with.&lt;/p&gt;
				&lt;p&gt;I then created a cron job that restarts each batch every hour, which looks like this:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0,1 * * * * /root/job.sh 1 1
				2,3 * * * * /root/job.sh 1 2
				15,16 * * * * /root/job.sh 2 1
				17,18 * * * * /root/job.sh 2 2
				30,31 * * * * /root/job.sh 3 1
				32,33 * * * * /root/job.sh 3 2
				45,46 * * * * /root/job.sh 4 1
				47,48 * * * * /root/job.sh 4 2
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;This way a batch of instances will get new IPs every hour, effectively bypassing Douban’s IP limitations, which is another key to the success of the 2nd-gen spider swarm.&lt;/p&gt;
				&lt;h3 id=&quot;part-3-results&quot;&gt;Results&lt;/h3&gt;
				&lt;p&gt;With everything set up, I packed up a new AMI for the spider client, copied the AMI to 3 other AWS regions, and launched as many instances as possible, giving a total of 126 spider clients running simultaneously.&lt;/p&gt;
				&lt;p&gt;This new spider swarm achieved almost twice the speed of the old version, at a sustained rate of around 1,700 records per second, when the old version could only maintain a burst speed of 900 records per second, before quickly dropping to 500 records per second. What’s more satisfactory was that it was fault-tolerant, finally crawling 20.7M records (out of a total of 21.6M) before completely stopped working after around 12 hours.&lt;/p&gt;
				&lt;p&gt;The crawled data covered more than 90% of the test set of the experiment, and boosted the RMSE value of our submission from 1.304 to a whopping 0.546. We managed to make it one step further to 0.539 by adding the crawled data to our training set. For the record, the 2nd place, who also played with web spiders, only managed to get the RMSE value to 0.87. This is a great success.&lt;/p&gt;
				&lt;p&gt;On a side note, you probably shouldn’t attempt this if you don’t have credits on AWS. This 3-day journey through AWS with a spider swarm cost me an astonishing amount of US$44.96, with more than $30 spent on EC2 and more than $10 spent on traffic (AWS charges for traffic beyond 1 GB). Fortunately, I have them all covered by my remaining credits from AWS Educate, making this whole crawler project an enjoyable experience.&lt;/p&gt;
				&lt;h2 id=&quot;gallery&quot;&gt;Gallery&lt;/h2&gt;
				&lt;figure class=&quot;third &quot;&gt;
				&lt;a href=&quot;/image/spider-aws/instances.us-west-1.png&quot; title=&quot;The EC2 instances screen on US West 1 region&quot;&gt;
				&lt;img src=&quot;/image/spider-aws/instances.us-west-1.png&quot; alt=&quot;AWS console&quot; /&gt;
				&lt;/a&gt;
				&lt;a href=&quot;/image/spider-aws/spiders-with-master.png&quot; title=&quot;In Tokyo region lies the « spider master »&quot;&gt;
				&lt;img src=&quot;/image/spider-aws/spiders-with-master.png&quot; alt=&quot;AWS console&quot; /&gt;
				&lt;/a&gt;
				&lt;a href=&quot;/image/spider-aws/shutting-down.png&quot; title=&quot;Job done, spiders are shut down now.&quot;&gt;
				&lt;img src=&quot;/image/spider-aws/shutting-down.png&quot; alt=&quot;AWS console&quot; /&gt;
				&lt;/a&gt;
				&lt;/figure&gt;</content><author><name>iBug</name></author><category term="web-scraping" /><category term="aws" /><category term="story" /><summary type="html">The 3rd-and-last experiment of course Web Information Processing and Application required us to create a recommendation engine, and “predict” the rating (1-5 stars) for 4M user-item pairs based on the training data of 9M user-item pairs and a social network.</summary></entry><entry><title type="html">Managing servers with OpenSSH Certificate Authority</title><link href="https://ibugone.com/blog/2019/12/manage-servers-with-ssh-ca/" rel="alternate" type="text/html" title="Managing servers with OpenSSH Certificate Authority" /><published>2019-12-23T00:00:00+00:00</published><updated>2019-12-26T18:24:54+00:00</updated><id>https://ibugone.com/blog/2019/12/manage-servers-with-ssh-ca</id><content type="html" xml:base="https://ibugone.com/blog/2019/12/manage-servers-with-ssh-ca/">&lt;p&gt;Since the addition of the website server for an external corporation, I now have 5 Linux servers to manage on my own. I also have 4 terminal devices that I use to connect to those servers: two of my laptops, my Android phone (using &lt;a href=&quot;https://termux.com/&quot;&gt;Termux&lt;/a&gt;), and one of those servers that I use as a workstation.&lt;/p&gt;
				&lt;p&gt;Managing SSH keys has always been a headache for this many computers, as all of them on one side have to be updated of the new key whenever one on the other side changes or rotates its key. In case of a client key change, the new key must be uploaded to all servers. And in a worse case where the original key is lost, the uploading needs to be done with the help of another client (computer or phone), which is an additional layer of unnecessary complexity and cumber.&lt;/p&gt;
				&lt;p&gt;Not until I took over a system of many servers did I learn about SSH CA. It’s for sure to the rescue!&lt;/p&gt;
				&lt;h2 id=&quot;what-is-an-ssh-ca&quot;&gt;What is an SSH CA?&lt;/h2&gt;
				&lt;p&gt;Long story short, an SSH Certificate Authority is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Certificate_authority&quot;&gt;certificate authority&lt;/a&gt; for SSH hosts. A client can trust all server signed by the CA by simply trusting the CA. And more powerfully, a server can &lt;em&gt;also&lt;/em&gt; trust all user keys if the user key has a signature from the CA, and the server trusts the CA for signing user keys.&lt;/p&gt;
				&lt;p&gt;By properly configuring servers and clients, a rotated or otherwise changed key, be it a host key or a user key, will no longer cause chaos of copying public keys from everywhere, to everywhere. The follow-up is as simple as getting another CA signature for the new key, and everything will go smoothly as if nothing has happened.&lt;/p&gt;
				&lt;h2 id=&quot;creating-an-ssh-ca&quot;&gt;Creating an SSH CA&lt;/h2&gt;
				&lt;p&gt;Creating a CA is as easy as generating a key pair for it, and publishing its public key.&lt;/p&gt;
				&lt;p&gt;To generate a key pair for a CA, you’d do it the usual way you generate a regular SSH key pair:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; my_ca
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Proceed through the prompts, and you’ll find two files &lt;code class=&quot;highlighter-rouge&quot;&gt;my_ca&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;my_ca.pub&lt;/code&gt; in your current directory. Contrary to SSH keys that you use for regular purposes, I highly recommend setting a password for this key, since it’s going to be &lt;em&gt;way&lt;/em&gt; more powerful than those. Protect the private key carefully, and leave the public part somewhere easily accessible, like &lt;a href=&quot;https://ibugone.com/assets/ssh-ca.pub.txt&quot;&gt;mine&lt;/a&gt;.&lt;/p&gt;
				&lt;h2 id=&quot;authenticating-hosts-with-ssh-ca&quot;&gt;Authenticating hosts with SSH CA&lt;/h2&gt;
				&lt;h3 id=&quot;sign-a-host-key&quot;&gt;Sign a host key&lt;/h3&gt;
				&lt;p&gt;To sign a host key with your CA, copy its &lt;strong&gt;public&lt;/strong&gt; part (like &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh_host_rsa_key.pub&lt;/code&gt;) to a convenient place, and run the following command.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &amp;lt;ca private key&amp;gt; &lt;span class=&quot;nt&quot;&gt;-I&lt;/span&gt; &amp;lt;signature name&amp;gt; &lt;span class=&quot;nt&quot;&gt;-h&lt;/span&gt; &amp;lt;host key&amp;gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;You’ll find a file named &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh_host_rsa_key-cert.pub&lt;/code&gt; in your current directory, which you should copy back to the server. Because sshd(8) doesn’t look for host certificates by default, you shold edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/ssh/sshd_config&lt;/code&gt; to instruct it to do so. Add this line to the file to let it work:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;HostCertificate /etc/ssh/ssh_host_rsa_key-cert.pub
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Then run &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl reload ssh&lt;/code&gt; (or &lt;code class=&quot;highlighter-rouge&quot;&gt;service sshd reload&lt;/code&gt; if you’re not running on systemd) to reload the configuration.&lt;/p&gt;
				&lt;h3 id=&quot;restrict-signature-validity-range&quot;&gt;Restrict signature validity range&lt;/h3&gt;
				&lt;p&gt;As a security measure, you probably don’t want the signature remain valid even if stolen. The &lt;code class=&quot;highlighter-rouge&quot;&gt;-n&lt;/code&gt; option is there for you to specify “valid principals”. For example, you can specify a signature valid for &lt;code class=&quot;highlighter-rouge&quot;&gt;s.ibugone.com,10.250.0.2&lt;/code&gt;, and this signature is accepted by clients only if the server is accessed from &lt;code class=&quot;highlighter-rouge&quot;&gt;s.ibugone.com&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;10.250.0.2&lt;/code&gt;. If someone steals the private key and the CA signature and installs it on another host, for example &lt;code class=&quot;highlighter-rouge&quot;&gt;q.ibugone.com&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;10.250.0.3&lt;/code&gt;, the SSH client will complain:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Certificate invalid: name is not a listed principal
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Unless the attacker can hijack your DNS (for authenticated domain names) or even your routers (for plain IP addresses), this signature is useless when stolen, and you can safely forget about it and sign a new one for the regenerated host key.&lt;/p&gt;
				&lt;div class=&quot;notice--primary&quot;&gt;
				&lt;h4 class=&quot;no_toc&quot; id=&quot;tip&quot;&gt;&lt;i class=&quot;far fa-lightbulb&quot;&gt;&lt;/i&gt; Tip&lt;/h4&gt;
				&lt;p&gt;You can see the certificate information using &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh-keygen -L&lt;/code&gt; command. For example:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen &lt;span class=&quot;nt&quot;&gt;-Lf&lt;/span&gt; /etc/ssh/ssh_host_rsa_key-cert.pub
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
				&lt;/div&gt;
				&lt;h3 id=&quot;configure-clients&quot;&gt;Configure clients&lt;/h3&gt;
				&lt;p&gt;Now let’s configure clients to trust CA signatures. You’ll need to publish the public key of the CA (as said before) so clients can easily acquire it. Put a line like this in a client’s &lt;code class=&quot;highlighter-rouge&quot;&gt;known_hosts&lt;/code&gt; file:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;@cert-authority * ssh-rsa &amp;lt;publicKeyGibberish&amp;gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;You can automate the addition of the above line using shell scripts:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;printf&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;@cert-authority * &quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; - my_ca.pub &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; ~/.ssh/known_hosts
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Now try SSHing into a host with a CA signature. You’ll notice that SSH doesn’t prompt for “unknown host” even if it’s not listed in the &lt;code class=&quot;highlighter-rouge&quot;&gt;known_hosts&lt;/code&gt; file, which is because of the magic of the &lt;code class=&quot;highlighter-rouge&quot;&gt;@cert-authority&lt;/code&gt; line. Should you be interested in the details, you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh -vvv&lt;/code&gt; to let SSH client generate extra information.&lt;/p&gt;
				&lt;h2 id=&quot;authenticating-users-with-ssh-ca&quot;&gt;Authenticating users with SSH CA&lt;/h2&gt;
				&lt;h3 id=&quot;configure-servers&quot;&gt;Configure servers&lt;/h3&gt;
				&lt;p&gt;We’ll start this part with server side configuration. We want the server to trust user certificates signed by the CA, so we’ll copy the CA’s public key onto the server, and again edit &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/ssh/sshd_config&lt;/code&gt; and add the following line.&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;TrustedUserCAKeys /etc/ssh/ssh_user_ca
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Make sure you’ve put the CA public key at &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/ssh/ssh_user_ca&lt;/code&gt;, or you should change the path in the above configuration accordingly. Again, run &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl reload ssh&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;service sshd reload&lt;/code&gt; to reload the SSH server.&lt;/p&gt;
				&lt;div class=&quot;notice--primary&quot;&gt;
				&lt;h4 class=&quot;no_toc&quot; id=&quot;pro-tip&quot;&gt;&lt;i class=&quot;far fa-lightbulb&quot;&gt;&lt;/i&gt; Pro Tip&lt;/h4&gt;
				&lt;p&gt;Did you notice that the configuration line is named CA&lt;strong&gt;Keys&lt;/strong&gt;, not just CA&lt;strong&gt;Key&lt;/strong&gt;? Yes, you can add multiple public keys to that file just like you’re already doing with &lt;code class=&quot;highlighter-rouge&quot;&gt;authorized_keys&lt;/code&gt; file.&lt;/p&gt;
				&lt;/div&gt;
				&lt;h3 id=&quot;sign-user-keys&quot;&gt;Sign user keys&lt;/h3&gt;
				&lt;p&gt;Now, to grant access to all servers configured this way to a user, ask for their public key and create a signature. The command is similar to that when signing a host certificate, except that there’s no &lt;code class=&quot;highlighter-rouge&quot;&gt;-h&lt;/code&gt; switch (it’s for signing hosts), and the &lt;code class=&quot;highlighter-rouge&quot;&gt;-n&lt;/code&gt; (named principals) option is mandatory this time.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ssh-keygen &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; my_ca &lt;span class=&quot;nt&quot;&gt;-I&lt;/span&gt; &amp;lt;user name&amp;gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; root,ubuntu id_rsa.pub
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;This will create a &lt;code class=&quot;highlighter-rouge&quot;&gt;id_rsa-cert.pub&lt;/code&gt; file under the current directory, which you want to send back to the user so they can use this signature to log in to servers.&lt;/p&gt;
				&lt;p&gt;Contrary to host signatures, the SSH client doesn’t need extra configuration, because it automatically looks for the certificate file by appending &lt;code class=&quot;highlighter-rouge&quot;&gt;-cert.pub&lt;/code&gt; to the name of the private key. Again you can use &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh -vvv&lt;/code&gt; to see what’s going on under the hood.&lt;/p&gt;
				&lt;h3 id=&quot;separating-access-to-different-hosts&quot;&gt;Separating access to different hosts&lt;/h3&gt;
				&lt;p&gt;As you’ve probably noticed, if you sign a user certificate with &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; being a listed principal, the corresponding private key can be used to log in as root on &lt;em&gt;ALL&lt;/em&gt; servers that trust the certificate authority. This is rarely a desired result, and you’re probably looking for a cure for the issue.&lt;/p&gt;
				&lt;p&gt;Fortunately, SSH supports an “authorized principals” setting, which allows granting access to users with specific “principals”. In general, you want separate authorized principals for different users on hosts. Here’s what you can start with, by enabling this setting in &lt;code class=&quot;highlighter-rouge&quot;&gt;sshd_config&lt;/code&gt;:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;AuthorizedPrincipalsFile /etc/ssh/authorized_principals/%u
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;You can then create lists of authorized names for each user under &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/ssh/authorized_principals&lt;/code&gt;. For example, you can have the following lines in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/ssh/authorized_principals/root&lt;/code&gt;:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;taokystrong
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;After reloading SSH server, users with a certificate containing &lt;code class=&quot;highlighter-rouge&quot;&gt;taokystrong&lt;/code&gt; as a listed principal (supplied by the &lt;code class=&quot;highlighter-rouge&quot;&gt;-n&lt;/code&gt; option when signing the certificate using &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh-keygen&lt;/code&gt;) can log in as root on this host (and &lt;code class=&quot;highlighter-rouge&quot;&gt;taokystrong&lt;/code&gt; as well), but not any other user on this host, or the root user on any other server. Note that certificates signed for &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; can still log in as root on any servers that trust this CA.&lt;/p&gt;
				&lt;div class=&quot;notice--primary&quot;&gt;
				&lt;h4 class=&quot;no_toc&quot; id=&quot;good-practices&quot;&gt;Good practices&lt;/h4&gt;
				&lt;p&gt;For personal uses, it’s perfectly fine to use one CA for both hosts and users, but in larger corporations with a complex server layout, it’s a general practice to use separate CAs for host authentication and user authentication.&lt;/p&gt;
				&lt;/div&gt;
				&lt;h2 id=&quot;other-tips&quot;&gt;Other tips&lt;/h2&gt;
				&lt;p&gt;OpenSSH is a complicated and powerful SSH ecosystem. There are far more available options than those described in this article. For example, certificates can have a “validity period”, and the commands can also be limited (instead of granting a full shell).&lt;/p&gt;
				&lt;p&gt;For more detailed and authoritative information about thses configuration, &lt;a href=&quot;https://linux.die.net/man/5/sshd_config&quot;&gt;the man page for &lt;code class=&quot;highlighter-rouge&quot;&gt;sshd_config&lt;/code&gt;&lt;/a&gt; is always a good point to look at.&lt;/p&gt;</content><author><name>iBug</name></author><category term="linux" /><category term="ssh" /><summary type="html">Since the addition of the website server for an external corporation, I now have 5 Linux servers to manage on my own. I also have 4 terminal devices that I use to connect to those servers: two of my laptops, my Android phone (using Termux), and one of those servers that I use as a workstation.</summary></entry><entry><title type="html">How to change email of your Nvidia account</title><link href="https://ibugone.com/blog/2019/11/change-nvidia-account-email/" rel="alternate" type="text/html" title="How to change email of your Nvidia account" /><published>2019-11-22T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/11/change-nvidia-account-email</id><content type="html" xml:base="https://ibugone.com/blog/2019/11/change-nvidia-account-email/">&lt;p&gt;I recently retired a few old email addresses, and am currently going in a row to change email for accounts associated with those emails. Everything else went smoothly, with my Nvidia account being an exception - There wasn’t an option to change it!&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/nv-account/main-page.png&quot; alt=&quot;no change option?!?&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;My first idea was to Google for solutions, and the first few results were on the GeForce forum saying you need to contact supprt. I did so, and ended up being told that emails can only be changed once per account, and there’s no more option to change it once more. What a terrible UX design!&lt;/p&gt;
				&lt;p&gt;I decided to give it a try to work around this. I first created another account and checked where the [Change Email] was located. Not any hard.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/nv-account/change-button.png&quot; alt=&quot;the change button&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;From a web developer’s perspective, it’s a must to open F12 Developer Tools and examine the button:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/nv-account/change-button-f12.png&quot; alt=&quot;the change button - examined&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Then I switched back to my old account and examined the same part of HTML:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/nv-account/change-button-disabled-f12.png&quot; alt=&quot;no change button - examined&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Now it seems clear to me: The last thing to do before succeeding is to purge that &lt;code class=&quot;highlighter-rouge&quot;&gt;display: none;&lt;/code&gt; from the button. Double-click on the text and you can delete it with ease:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/nv-account/removing-style.png&quot; alt=&quot;remove display none&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Voilà! You can now click it to change email for your Nvidia account. Why on earth did they decide that email can only be changed once per account? It sucks!&lt;/p&gt;</content><author><name>iBug</name></author><category term="lifehack" /><summary type="html">I recently retired a few old email addresses, and am currently going in a row to change email for accounts associated with those emails. Everything else went smoothly, with my Nvidia account being an exception - There wasn’t an option to change it!</summary></entry><entry><title type="html">Make your GitHub Pages website faster with Cloudflare</title><link href="https://ibugone.com/blog/2019/11/optimize-github-pages-with-cloudflare/" rel="alternate" type="text/html" title="Make your GitHub Pages website faster with Cloudflare" /><published>2019-11-11T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/11/optimize-github-pages-with-cloudflare</id><content type="html" xml:base="https://ibugone.com/blog/2019/11/optimize-github-pages-with-cloudflare/">&lt;p&gt;This September I employed Cloudflare to optimize my website (&lt;a href=&quot;https://ibugone.com&quot;&gt;https://ibugone.com&lt;/a&gt;) in various aspects. It turned out to be a brilliant move and Cloudflare has proved to be a great service to have.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/homepage.jpg&quot; alt=&quot;Landing page of my website&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;h2 id=&quot;benefits&quot;&gt;Benefits&lt;/h2&gt;
				&lt;h3 id=&quot;faster-site-loading&quot;&gt;Faster site loading&lt;/h3&gt;
				&lt;p&gt;While I haven’t made strict benchmarks, people all over the world have reported that my website loads faster and smoother than before.&lt;/p&gt;
				&lt;p&gt;My website is a Jekyll-generated static site, hosted with &lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt;. Currently (August 2019) GitHub provides 4 IPs that are actually behind Fastly CDN, making all GitHub Pages website rather fast already given Fastly’s global point of presence (PoP).&lt;/p&gt;
				&lt;div class=&quot;notice--primary&quot;&gt;
				&lt;h4 id=&quot;did-you-know&quot;&gt;Did you know&lt;/h4&gt;
				&lt;p&gt;You can examine the &lt;code class=&quot;highlighter-rouge&quot;&gt;X-Served-By&lt;/code&gt; header of the response from GitHub Pages servers to see which edge location your website is served from. For example:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt; https://ibug.github.io/ &lt;span class=&quot;nt&quot;&gt;-H&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Host: ibugone.com'&lt;/span&gt;
				...
				X-Served-By: cache-tyo19946-TYO
				...
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;  &lt;/div&gt;
				&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;TYO&lt;/code&gt; key indicates that my request went through Fastly’s Tokyo endpoint.&lt;/p&gt;
				&lt;/div&gt;
				&lt;p&gt;Interestingly, the version of Fastly CDN uses the same technology as Cloudflare that I’m introducing below, which is &lt;a href=&quot;https://en.wikipedia.org/wiki/Anycast&quot;&gt;Anycast&lt;/a&gt;. What makes Cloudflare stand out is &lt;a href=&quot;https://www.codeinwp.com/blog/maxcdn-vs-cloudflare-vs-cloudfront-vs-akamai-edge-vs-fastly/#locations&quot;&gt;its global points of presence&lt;/a&gt; - virtually everywhere and goes behind only Akamai.&lt;/p&gt;
				&lt;h3 id=&quot;http-settings&quot;&gt;Custom behavior of HTTP response&lt;/h3&gt;
				&lt;p&gt;If you host your site on vanilla GitHub Pages, there’s not much you can do with HTTP response, like cache control and redirects. By default, GitHub Pages sets all expiration times for static assets to 10 minutes, but for sure you may want certain files to be cached for longer. Like me, I would like all images on my site to be cached for as long as possible, which is not possible with GitHub Pages on its own.&lt;/p&gt;
				&lt;p&gt;Cloudflare offers a variety of tweaks via Page Rules, so I could achieve my goal with a Page Rule setting:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/cloudflare/image-caching.png&quot; alt=&quot;My Cloudflare setting for image caching&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Instead of fetching an identical copy from GitHub Pages’ origin server, browsers will now cache all image on my website for a year, and Cloudflare’s CDN servers will cache my images for up to 30 days. Other available options include redirection and performance optimizations, and it’s up to you to explore them all.&lt;/p&gt;
				&lt;h3 id=&quot;more-secure-https-settings&quot;&gt;More secure HTTPS settings&lt;/h3&gt;
				&lt;p&gt;Some time ago, GitHub Pages didn’t support HTTPS with custom domains, which was quite a downside for such a popular service. At that time, Cloudflare was almost the only option to add HTTPS support to your website. While now this is no longer the case, there’re still some weaknesses and limitations, for example the lack of support for HSTS and the occasional failure of renewing an SSL certificate. With Cloudflare you can add HSTS headers to all responses coming from your website, further improving security.&lt;/p&gt;
				&lt;h2 id=&quot;the-setup&quot;&gt;The setup&lt;/h2&gt;
				&lt;h3 id=&quot;get-your-custom-domain-onto-cloudflare&quot;&gt;Get your custom domain onto Cloudflare&lt;/h3&gt;
				&lt;p&gt;Besides CDN, Cloudflare is also a fantastic DNS provider. To get started with Cloudflare, you’ll first move your domain’s DNS to Cloudflare. &lt;a href=&quot;https://dash.cloudflare.com/sign-up&quot;&gt;Sign up&lt;/a&gt; if you don’t already have an account.&lt;/p&gt;
				&lt;p&gt;Next, you’ll be prompted for the domain you want to add to Cloudflare. Enter the domain and Cloudflare will perform a quick scan of all records, and you can manually review them and add missing records, if any.&lt;/p&gt;
				&lt;p&gt;To enable Cloudflare CDN for domains under which you run a website, click the grey cloud icon so it becomes orange. This means that website will be proxied and delivered via Cloudflare, and its DNS record will instead resolve to some of Cloudflare’s IPs.&lt;/p&gt;
				&lt;p&gt;That’s all, isn’t it simple? But wait, there’s more that Cloudflare provides, and you can now explore all of them and see which fits your needs.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/cloudflare/apps.png&quot; alt=&quot;Apps that Cloudflare provides&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;h3 id=&quot;using-page-rules&quot;&gt;Using Page Rules&lt;/h3&gt;
				&lt;p&gt;Let’s turn our focus onto the Page Rules app. With Page Rules you can configure Cloudflare behavior on specific “routes”, or URL patterns. One common use case is to create a permanent redirect from your &lt;code class=&quot;highlighter-rouge&quot;&gt;www&lt;/code&gt; domain to your apex domain, or in the reverse direction.&lt;/p&gt;
				&lt;p&gt;For example, if I want to create a permanent redirect from &lt;code class=&quot;highlighter-rouge&quot;&gt;www.ibugone.com&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;ibugone.com&lt;/code&gt;, I would create a Page Rule like this:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/cloudflare/page-rule-301.png&quot; alt=&quot;Page Rule for 301 redirection from www.ibugone.com to ibugone.com&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;And there’s an aggressive image caching setting &lt;a href=&quot;#http-settings&quot;&gt;described before&lt;/a&gt;. There are many Page Rule options for you to explore, and there are always one or more that fits your needs.&lt;/p&gt;
				&lt;h3 id=&quot;more-features&quot;&gt;Get the best out of Cloudflare&lt;/h3&gt;
				&lt;p&gt;For newer webmasters, you might want to ensure &lt;strong&gt;SSL / TLS&lt;/strong&gt; works as expected. The &lt;strong&gt;Full&lt;/strong&gt; mode makes Cloudflare fetch original content from your website via HTTPS without validating the certificate on your server. For GitHub Pages this is the option you generally want, as GitHub Pages presents its default certificate for &lt;code class=&quot;highlighter-rouge&quot;&gt;*.github.io&lt;/code&gt; if it doesn’t have a certificate for your domain. This is good enough for your website behind Cloudflare.&lt;/p&gt;
				&lt;p&gt;You can also enable better security by enabling latest security features in &lt;strong&gt;Edge Certificates&lt;/strong&gt; tab of the &lt;strong&gt;SSL / TLS&lt;/strong&gt; app, where you can set the minimum SSL version (TLS 1.2 recommended) and enable automatic HTTPS redirection. This will not only make your website more secure to visitors, but also give you a boost in SEO, as modern search engines favor HTTPS websites over HTTP ones. Though, you might not want to jump straight to HSTS before you’re absolutely ready (see &lt;a href=&quot;https://support.cloudflare.com/hc/en-us/articles/204183088-Understanding-HSTS-HTTP-Strict-Transport-Security-&quot;&gt;Cloudflare article&lt;/a&gt;).&lt;/p&gt;
				&lt;div class=&quot;notice--primary&quot;&gt;
				&lt;p&gt;I have moved the entire domain &lt;code class=&quot;highlighter-rouge&quot;&gt;ibugone.com&lt;/code&gt; onto HSTS and get it preloaded because I’m confident I can handle it.&lt;/p&gt;
				&lt;/div&gt;
				&lt;p&gt;You may also want to tune your website for better performance by changing the settings under the &lt;strong&gt;Speed&lt;/strong&gt; app, for example enabling HTTP/2 and auto minifying.&lt;/p&gt;
				&lt;h2 id=&quot;further-reading&quot;&gt;Further reading&lt;/h2&gt;
				&lt;ul&gt;
				&lt;li&gt;Cloudflare has &lt;a href=&quot;https://blog.cloudflare.com/secure-and-fast-github-pages-with-cloudflare/&quot;&gt;an official blog&lt;/a&gt; on introducing Cloudflare to GitHub Pages, and it’s actually a start-from-scratch tutorial for creating a static website and then deploying Cloudflare CDN over it.&lt;/li&gt;
				&lt;/ul&gt;</content><author><name>iBug</name></author><category term="github-pages" /><category term="cloudflare" /><summary type="html">This September I employed Cloudflare to optimize my website (https://ibugone.com) in various aspects. It turned out to be a brilliant move and Cloudflare has proved to be a great service to have.</summary></entry><entry><title type="html">Converting DFA to Regular Expression</title><link href="https://ibugone.com/blog/2019/09/convert-dfa-to-regex/" rel="alternate" type="text/html" title="Converting DFA to Regular Expression" /><published>2019-09-25T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/09/convert-dfa-to-regex</id><content type="html" xml:base="https://ibugone.com/blog/2019/09/convert-dfa-to-regex/">&lt;p&gt;This post originated from Lab 1 of course &lt;em&gt;Compilers: Principles&lt;/em&gt; that I’m currently taking, in which we were required to write a &lt;code class=&quot;highlighter-rouge&quot;&gt;flex&lt;/code&gt; program to parse a subset of the C language. The multiline comment &lt;code class=&quot;highlighter-rouge&quot;&gt;/* */&lt;/code&gt; was the most troublesome to handle for most of us (excluding me, for sure).&lt;/p&gt;
				&lt;h2 id=&quot;the-process&quot;&gt;The process&lt;/h2&gt;
				&lt;p&gt;I’ll assume you’ve already drawn a DFA for the multiline-comment structure, so here it is:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/dfa-comment.png&quot; alt=&quot;DFA for the multiline comment&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;We’re first going to turn it into “state transformation equations”, so it looks like this:&lt;/p&gt;
				&lt;script type=&quot;math/tex; mode=display&quot;&gt;A = \texttt{/*} \mid A\texttt{[^*]} \mid B\texttt{[^*/]}
				\\
				B = A\texttt{*} \mid B\texttt{*}
				\\
				C = B\texttt{/}&lt;/script&gt;
				&lt;p&gt;The first step we’re taking is to realize that $A=S \mid Aa$ is easily found to be equivalent to $A = Sa^*$, where the superscript asterisk means “repeat 0 or more times”. So $B$ can be turned into&lt;/p&gt;
				&lt;script type=&quot;math/tex; mode=display&quot;&gt;B = A\texttt{**}^* = A\texttt{*}^+&lt;/script&gt;
				&lt;p&gt;Again, the superscript plus means “repeat 1 or more times” as the same in PCRE.&lt;/p&gt;
				&lt;p&gt;Now it’s time to substitute $B$ with its simplified expression:&lt;/p&gt;
				&lt;script type=&quot;math/tex; mode=display&quot;&gt;A =  \texttt{/*} \mid A\texttt{[^*]} \mid A\texttt{*}^+\texttt{[^*/]}
				\\
				C = A\texttt{*}^+\texttt{/}&lt;/script&gt;
				&lt;p&gt;Note that there’s a &lt;em&gt;distributive property&lt;/em&gt; here, which described using symbols, is that $Aa \mid Ab = A(a\mid b)$, so now we have&lt;/p&gt;
				&lt;script type=&quot;math/tex; mode=display&quot;&gt;A = \texttt{/*} \mid A\ (\texttt{[^*]} \mid \texttt{*}^+\texttt{[^*/]})&lt;/script&gt;
				&lt;p&gt;Applying the first transformation $A = S \mid Aa = Sa^*$, we have&lt;/p&gt;
				&lt;script type=&quot;math/tex; mode=display&quot;&gt;A = \texttt{/*}\ (\texttt{[^*]} \mid \texttt{*}^+\texttt{[^*/]})^*&lt;/script&gt;
				&lt;p&gt;Now there’s no recursion in the new “state transformation equation”, so we can substitute $A$ with this final expression and get the regular expression for $C$, the result we want:&lt;/p&gt;
				&lt;script type=&quot;math/tex; mode=display&quot;&gt;C = A\texttt{*}^+\texttt{/} =
				\texttt{/*}\ (\texttt{[^*]} \mid \texttt{*}^+\texttt{[^*/]})^*\ \texttt{*}^+\texttt{/}&lt;/script&gt;
				&lt;p&gt;Converting the above regular expression to code, we now have&lt;/p&gt;
				&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;C = \/\*([^*]|\*+[^*/])*\*+\/
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;h3 id=&quot;try-it-online-with-regex101&quot;&gt;&lt;a href=&quot;https://regex101.com/r/qAog6Z/1&quot;&gt;Try it online with RegEx101!&lt;/a&gt;&lt;/h3&gt;
				&lt;hr /&gt;
				&lt;p&gt;Now can you imagine how to use regular expressions to match multiples of 3 (base 10)? Yes, it’s entirely possible. See &lt;a href=&quot;https://www.quaxio.com/triple/&quot;&gt;this fantastic article &lt;i class=&quot;fa fas fa-xs fa-external-link-alt&quot;&gt;&lt;/i&gt;&lt;/a&gt; for details, which uses essentially the same techniques to convert a DFA (or a finite-state machine) to a regular expression that does the job.&lt;/p&gt;</content><author><name>iBug</name></author><category term="study-notes" /><category term="regular-expression" /><summary type="html">This post originated from Lab 1 of course Compilers: Principles that I’m currently taking, in which we were required to write a flex program to parse a subset of the C language. The multiline comment /* */ was the most troublesome to handle for most of us (excluding me, for sure).</summary></entry><entry><title type="html">Raspberry Pi 4 B Review and Benchmark - What’s improved over Pi 3 B+</title><link href="https://ibugone.com/blog/2019/09/raspberry-pi-4-review-benchmark/" rel="alternate" type="text/html" title="Raspberry Pi 4 B Review and Benchmark - What's improved over Pi 3 B+" /><published>2019-09-10T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/09/raspberry-pi-4-review-benchmark</id><content type="html" xml:base="https://ibugone.com/blog/2019/09/raspberry-pi-4-review-benchmark/">&lt;p&gt;Lately I’ve finally received my Raspberry Pi 4 (4 GB model), and I couldn’t resist the temptation to give it a try and see all the improvements that’s been reported for months.&lt;/p&gt;
				&lt;p&gt;As I’ve got one with my Pi 3 B+, I also ordered an aluminum “case” that can ease the ache of heating. One major difference is that the new cooling case is armed with two little fans, which is a rather huge boost in speed of heat dissipation.&lt;/p&gt;
				&lt;p&gt;So let’s take a look at the new Pi 4.&lt;/p&gt;
				&lt;h2 id=&quot;overview&quot;&gt;Overview&lt;/h2&gt;
				&lt;figure class=&quot;third &quot;&gt;
				&lt;a href=&quot;/image/rpi4/box.jpg&quot; title=&quot;Package of Raspberry Pi 4&quot;&gt;
				&lt;img src=&quot;/image/rpi4/box.jpg&quot; alt=&quot;Package of Raspberry Pi 4&quot; /&gt;
				&lt;/a&gt;
				&lt;a href=&quot;/image/rpi4/box-bottom.jpg&quot; title=&quot;Bottom of the package&quot;&gt;
				&lt;img src=&quot;/image/rpi4/box-bottom.jpg&quot; alt=&quot;Bottom of the package&quot; /&gt;
				&lt;/a&gt;
				&lt;a href=&quot;/image/rpi4/box-open.jpg&quot; title=&quot;Opening the package&quot;&gt;
				&lt;img src=&quot;/image/rpi4/box-open.jpg&quot; alt=&quot;The package is open&quot; /&gt;
				&lt;/a&gt;
				&lt;/figure&gt;
				&lt;p&gt;The new Pi 4 is wrapped in a box similar to that of Pi 3 B+, with a white outline of the Pi 4 in 1:1 scale on a red background. Unlike Pi 3 B, neither 3 B+ and 4 has a electrostatic-proof bag around them in the box. This isn’t anything of a problem, though.&lt;/p&gt;
				&lt;p&gt;The new Pi 4 has a similar form factor as its predecessors, with a few noticeable differences, among which the USB 3.0 ports is the first to spot, as they’re marked blue. As you inspect the USB 3.0 ports, you probably have noticed that the Ethernet port changed its position as well, which is likely due to the upgrade to a true gigabit port.&lt;/p&gt;
				&lt;figure class=&quot;third &quot;&gt;
				&lt;a href=&quot;/image/rpi4/overview.jpg&quot; title=&quot;Overview of Raspberry Pi 4&quot;&gt;
				&lt;img src=&quot;/image/rpi4/overview.jpg&quot; alt=&quot;Overview of Raspberry Pi 4&quot; /&gt;
				&lt;/a&gt;
				&lt;a href=&quot;/image/rpi4/overview-usb.jpg&quot; title=&quot;The USB ports and the Ethernet port&quot;&gt;
				&lt;img src=&quot;/image/rpi4/overview-usb.jpg&quot; alt=&quot;Raspberry Pi 4 on top of the box, showing the USB ports and the Ethernet port&quot; /&gt;
				&lt;/a&gt;
				&lt;a href=&quot;/image/rpi4/overview-side-ports.jpg&quot; title=&quot;The USB Type-C port and the HDMI ports&quot;&gt;
				&lt;img src=&quot;/image/rpi4/overview-side-ports.jpg&quot; alt=&quot;Focusing on the USB Type-C port and the HDMI ports&quot; /&gt;
				&lt;/a&gt;
				&lt;/figure&gt;
				&lt;p&gt;Some smaller ports, namely the power supply and the video output, have changed as well. The Pi 4 now requires a Type-C cable for power, and the requirement has raised to 5V / 3A. It’s unknown whether the Pi 4 accepts advanced charging protocols like Qualcomm Quick Charge or USB PD, but user reports goes against such assumptions. The standard-size HDMI on older models has also been replaced by micro-HDMI port, pardon, &lt;em&gt;ports&lt;/em&gt;. Yes, there are two, and both of them supports 4K @ 60 fps output, at the same time. While I’m planning to use this Pi as a headless server, people who use it as a desktop may find it favorable.&lt;/p&gt;
				&lt;p&gt;The RAM chip has also been moved from the back of the board to the front, alongside the SoC, which has an identical look as that on Pi 3 B+, but with a completely different heart under the skins. The Wi-Fi case and antenna remain unchanged, and there’s an extra chip in front of the gigabit ethernet port.&lt;/p&gt;
				&lt;h2 id=&quot;specs&quot;&gt;Specs&lt;/h2&gt;
				&lt;p&gt;It’s an exciting news that the new Pi 4 brings a wire range of solid and concrete upgrades, namely&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;Broadcom BCM2711 SoC, quad-core Cortex-A72 CPU @ 1.5 GHz&lt;/li&gt;
				&lt;li&gt;Comes in variations of 1 GB, 2 GB and &lt;strong&gt;4 GB RAM&lt;/strong&gt; (reviewed)&lt;/li&gt;
				&lt;li&gt;Broadcom VideoCore VI GPU&lt;/li&gt;
				&lt;li&gt;True Gigabit ethernet port&lt;/li&gt;
				&lt;li&gt;Bluetooth 5.0&lt;/li&gt;
				&lt;li&gt;Native USB 3.0 interface, with two Type-A ports&lt;/li&gt;
				&lt;li&gt;Dual HDMI port, supporting 4K @ 60 fps simultaneously&lt;/li&gt;
				&lt;li&gt;Faster microSD card slot&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;In later benchmarks, you’ll see what these upgrades really mean. Here’s a table for comparison:&lt;/p&gt;
				&lt;table&gt;
				&lt;thead&gt;
				&lt;tr&gt;
				&lt;th&gt;Item&lt;/th&gt;
				&lt;th style=&quot;text-align: center&quot;&gt;Pi 3 B&lt;/th&gt;
				&lt;th style=&quot;text-align: center&quot;&gt;Pi 3 B+&lt;/th&gt;
				&lt;th style=&quot;text-align: center&quot;&gt;Pi 4&lt;/th&gt;
				&lt;/tr&gt;
				&lt;/thead&gt;
				&lt;tbody&gt;
				&lt;tr&gt;
				&lt;td&gt;CPU&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;Quad-core&lt;br /&gt;Cortex-A53 @ 1.20 GHz&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;Quad-core&lt;br /&gt;Cortex-A53 @ 1.40 GHz&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;Quad-core&lt;br /&gt;Cortex-A72 @ 1.50 GHz&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;RAM&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;1 GB DDR2&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;1 GB DDR2&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;1 / 2 / &lt;strong&gt;4&lt;/strong&gt; GB DDR4&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;GPU&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;VideoCore IV&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;VideoCore IV&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;VideoCore VI&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;Ethernet&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;100 Mbps&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;300 Mbps effective&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;1 Gbps&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;Wi-Fi&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;2.4 GHz&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;2.4 GHz / 5 GHz&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;2.4 GHz / 5 GHz&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;Bluetooth&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;4.0&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;4.2&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;5.0&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;USB&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;4 * USB 2.0&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;4 * USB 2.0&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;2 * USB 2.0 + 2 * USB 3.0&lt;/td&gt;
				&lt;/tr&gt;
				&lt;tr&gt;
				&lt;td&gt;Price&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;$35&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;$35&lt;/td&gt;
				&lt;td style=&quot;text-align: center&quot;&gt;$35 / $45 / &lt;strong&gt;$55&lt;/strong&gt;&lt;br /&gt;Depending on RAM&lt;/td&gt;
				&lt;/tr&gt;
				&lt;/tbody&gt;
				&lt;/table&gt;
				&lt;p&gt;My Pi 3 B was sold soon after I got a 3 B+, so unfortunately there isn’t one participating this review.&lt;/p&gt;
				&lt;h2 id=&quot;setup&quot;&gt;My setup&lt;/h2&gt;
				&lt;figure class=&quot; &quot;&gt;
				&lt;a href=&quot;/image/rpi4/rpis-powered.jpg&quot; title=&quot;Both Raspberry Pis, powered through their GPIO pins&quot;&gt;
				&lt;img src=&quot;/image/rpi4/rpis-powered.jpg&quot; alt=&quot;Both Raspberry Pis, powered through their GPIO pins&quot; /&gt;
				&lt;/a&gt;
				&lt;/figure&gt;
				&lt;p&gt;As seen above, both Pis are set up as headless servers, with only power and ethernet connected. You’re probably wondering why they look so strange, which is because my laboratory provides a lot of these power supplies rated 5V / 6A, so I just took one and use it to power both Pis through GPIO. The two Pis are rated 5V / 2.5A and 5V / 3A each (peak), which this single power supply should be able to handle without difficulty.&lt;/p&gt;
				&lt;blockquote&gt;
				&lt;p&gt;&lt;strong&gt;WARNING&lt;/strong&gt;: Do NOT power your Raspberry Pi through GPIO unless you have stable power supply. Phone chargers aren’t &lt;em&gt;power supplies&lt;/em&gt; and should not be used to provide power in this way.&lt;/p&gt;
				&lt;/blockquote&gt;
				&lt;h2 id=&quot;benchmarking&quot;&gt;Benchmarking&lt;/h2&gt;
				&lt;p&gt;The Pis have static IP assigned and all operation is done over SSH. Operating system is latest Raspbian Buster Lite.&lt;/p&gt;
				&lt;h3 id=&quot;cpu&quot;&gt;1. SysBench CPU test&lt;/h3&gt;
				&lt;p&gt;SysBench is a benchmark suite that allows you to quickly get an impression of system performance. Here I use SysBench for CPU and Memory tests.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cpu run
				sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cpu &lt;span class=&quot;nt&quot;&gt;--num-threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4 run
				sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;cpu &lt;span class=&quot;nt&quot;&gt;--num-threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;8 run
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/sysbench-cpu.png&quot; alt=&quot;SysBench CPU test result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;As shown in the chart, the Pi 4 has a decent improvement over Pi 3 B+ in terms of CPU performance, taking 19.3% less time to complete the SysBench test in all scenarios.&lt;/p&gt;
				&lt;h3 id=&quot;2-sysbench-memory-test&quot;&gt;2. SysBench memory test&lt;/h3&gt;
				&lt;p&gt;The memory test is a little bit complicated, and some unexpected results uncovers.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;memory &lt;span class=&quot;nt&quot;&gt;--memory-block-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1K &lt;span class=&quot;nt&quot;&gt;--memory-total-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2G &lt;span class=&quot;nt&quot;&gt;--memory-oper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read &lt;/span&gt;run
				sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;memory &lt;span class=&quot;nt&quot;&gt;--memory-block-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1K &lt;span class=&quot;nt&quot;&gt;--memory-total-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2G &lt;span class=&quot;nt&quot;&gt;--memory-oper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;write run
				sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;memory &lt;span class=&quot;nt&quot;&gt;--memory-block-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1K &lt;span class=&quot;nt&quot;&gt;--memory-total-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2G &lt;span class=&quot;nt&quot;&gt;--memory-oper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--num-threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4 run
				sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;memory &lt;span class=&quot;nt&quot;&gt;--memory-block-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1K &lt;span class=&quot;nt&quot;&gt;--memory-total-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2G &lt;span class=&quot;nt&quot;&gt;--memory-oper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;write &lt;span class=&quot;nt&quot;&gt;--num-threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4 run
				sysbench &lt;span class=&quot;nt&quot;&gt;--test&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;memory &lt;span class=&quot;nt&quot;&gt;--memory-block-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1M &lt;span class=&quot;nt&quot;&gt;--memory-total-size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;2G &lt;span class=&quot;nt&quot;&gt;--memory-oper&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;write &lt;span class=&quot;nt&quot;&gt;--num-threads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4 run
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/sysbench-memory.png&quot; alt=&quot;SysBench memory test result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;It’s very surprising to see the new DDR4 performs worse than the decades-old DDR2 memory, and even astonishing to see that multithreading makes the gap bigger. The only thing reasonable to me is that when a single block goes to 1 MiB, the Pi 4 outperforms the Pi 3 B+ slightly.&lt;/p&gt;
				&lt;p&gt;There’s one interesting thing, though, that why I didn’t include a “1 MiB Read MT” column. SysBench reported a read speed of over 200 GB/s on both boards, and the results can sometimes go up to 500 GB/s, which is ridiculous to be taken seriously, so I just dropped that result.&lt;/p&gt;
				&lt;h3 id=&quot;3-fio-microsd-card-speed-test&quot;&gt;3. FIO microSD card speed test&lt;/h3&gt;
				&lt;p&gt;This test may depend on the microSD card, so I took out my (known) fastest cards for the Pis, the Lexar 667x 128 GB microSD card, which looks like below:&lt;/p&gt;
				&lt;center&gt;
				&lt;img src=&quot;/image/rpi4/microsd-card.jpg&quot; alt=&quot;The microSD card&quot; width=&quot;30%&quot; /&gt;
				&lt;/center&gt;
				&lt;p&gt;I use &lt;code class=&quot;highlighter-rouge&quot;&gt;fio&lt;/code&gt; for the disk (microSD card) I/O performance testing tool. Because I’m familiar with Crystal DiskMark, I tuned the command-line options of &lt;code class=&quot;highlighter-rouge&quot;&gt;fio&lt;/code&gt; to match the specs of CDM.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fio &lt;span class=&quot;nt&quot;&gt;--loops&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;5 &lt;span class=&quot;nt&quot;&gt;--size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;500m &lt;span class=&quot;nt&quot;&gt;--filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;fiotest.tmp &lt;span class=&quot;nt&quot;&gt;--stonewall&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--ioengine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;libaio &lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;SeqRead &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1m &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;SeqWrite &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1m &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;write &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;512Kread &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;512k &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;randread &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;512Kwrite &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;512k &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;randwrite &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4KQD32read &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4k &lt;span class=&quot;nt&quot;&gt;--iodepth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;32 &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;randread &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4KQD32write &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4k &lt;span class=&quot;nt&quot;&gt;--iodepth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;32 &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;randwrite &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4Kread &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4k &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;randread &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4Kwrite &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;4k &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;randwrite
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/fio-microsd.png&quot; alt=&quot;FIO microSD test result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;From the results we can see a huge boost on Pi 4, running 50% faster than its predecessor in many tests. This is probably the most useful upgrades on Pi 4, as the performance has always been constrained by the slow disk I/O.&lt;/p&gt;
				&lt;h3 id=&quot;4-p7zip-benchmark&quot;&gt;4. p7zip benchmark&lt;/h3&gt;
				&lt;p&gt;7-Zip has a built-in benchmarking tool, and so does its POSIX port &lt;code class=&quot;highlighter-rouge&quot;&gt;p7zip&lt;/code&gt;. I use this tool to test the compression and decompression performance on the Pis.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;7zr b &lt;span class=&quot;nt&quot;&gt;-mmt1&lt;/span&gt;
				7zr b
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/p7zip.png&quot; alt=&quot;p7zip benchmark result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;As &lt;a href=&quot;https://sevenzip.osdn.jp/chm/cmdline/commands/bench.htm&quot;&gt;the help article&lt;/a&gt; says, compression depends more on the throughput and latency of memory, which is likely the reason that the gap between the two Pis is bigger in compression test. After all, there’s a boost of 1/3 in the p7zip test.&lt;/p&gt;
				&lt;h3 id=&quot;5-openssl-speed-test&quot;&gt;5. OpenSSL speed test&lt;/h3&gt;
				&lt;p&gt;OpenSSL is the most prevalent crypto library, and it also has built-in speed test as well. The result is the fastest speed among all block sizes, which is always 16,384 bytes in all 4 tests.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;openssl speed &lt;span class=&quot;nt&quot;&gt;-evp&lt;/span&gt; aes-256-cbc
				openssl speed &lt;span class=&quot;nt&quot;&gt;-evp&lt;/span&gt; aes-256-gcm
				openssl speed &lt;span class=&quot;nt&quot;&gt;-evp&lt;/span&gt; sha1
				openssl speed &lt;span class=&quot;nt&quot;&gt;-evp&lt;/span&gt; sha256
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/openssl.png&quot; alt=&quot;OpenSSL speed result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;h3 id=&quot;6-network-speed-test&quot;&gt;6. Network speed test&lt;/h3&gt;
				&lt;p&gt;The Pi 4 upgraded the 300 Mbps Ethernet port to a true 1 Gbps port, which is a great benefit if you want to use it as an offline downloader or an NAS. Here I ran two tests about the network connectivity.&lt;/p&gt;
				&lt;h4 id=&quot;61-curl-file-download-test&quot;&gt;6.1 cURL file download test&lt;/h4&gt;
				&lt;p&gt;This one is simple: Use cURL to download a file from a LAN machine and see the speed.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/cURL.png&quot; alt=&quot;cURL download speed chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;The result isn’t as expected: The Pi 4 failed to run at its true Gbps speed, while my x86 Linux box right beside it made it.&lt;/p&gt;
				&lt;h4 id=&quot;62-nginx-performance-test&quot;&gt;6.2 NGINX performance test&lt;/h4&gt;
				&lt;p&gt;Another common use case is to serve web content with NGINX (sorry, no Apache). I installed NGINX on both Pis, set &lt;code class=&quot;highlighter-rouge&quot;&gt;access_log off&lt;/code&gt; and use Siege 4.0.4 on my x86 box to benchmark the servers.&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;siege &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; 10 &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; 1000 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host]
				siege &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; 25 &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; 400 &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;host]
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/nginx.png&quot; alt=&quot;Siege NGINX result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;With the increase in both CPU performance and network speed, the new Pi 4 runs almost twice as efficient as the Pi 3 B+. Surely a good news for the websiters.&lt;/p&gt;
				&lt;h3 id=&quot;7-application-performance&quot;&gt;7. Application performance&lt;/h3&gt;
				&lt;p&gt;I picked two of my favorite platforms, Python and Ruby (I’m not familiar with Node) for this test.&lt;/p&gt;
				&lt;p&gt;The Python test involves a stupid script taken from &lt;a href=&quot;&quot;&gt;this Stack Overflow answer&lt;/a&gt;, and the time is taken as the result.&lt;/p&gt;
				&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
				&lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;Stupid test function&quot;&quot;&quot;&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;lst&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
				&lt;span class=&quot;n&quot;&gt;lst&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
				&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;timeit&lt;/span&gt;
				&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;timeit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;test()&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;setup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;from __main__ import test&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;The Ruby test is simpler: Using Jekyll to build this site and see the time taken.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/python-ruby.png&quot; alt=&quot;Application test result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;The Ruby test is more balanced than the Python test, which is pure computational performance. As a result, the performance gap is smaller in the Ruby test.&lt;/p&gt;
				&lt;p&gt;Wait, that doesn’t mean the Pi 4 would be a good platform for your bigger Python or Ruby project. The same tests run &lt;strong&gt;10x faster&lt;/strong&gt; on my x86 Linux box (i7-8850H, 32 GB DDR4, NVMe SSD), running the Python script in 5 seconds and building my Jekyll site in 4 seconds. Well, you can’t expect a beefy computer from only a board costing $55, n’est-ce pas?&lt;/p&gt;
				&lt;h3 id=&quot;8-usb-io-performance&quot;&gt;8. USB I/O performance&lt;/h3&gt;
				&lt;p&gt;I took out my USB 3.1 SSD (assembled with a LiteOn L9M 512 GB and an enclosure case with VL716 SATA-to-USB adapter chip). However, as soon as I plug the SSD into either Pi, it powers down immediately. This later turns out to be the issue with power supply (GPIO pins can’t pass enough power), so I came back the day after and started the Pis with power supply from the Micro USB / Type-C port. This time the Pi 3 B+ works correctly and ran through the &lt;code class=&quot;highlighter-rouge&quot;&gt;fio&lt;/code&gt; test. The Pi 4, however, drops the SSD during the test due to power supply, &lt;em&gt;again&lt;/em&gt;. I ended up powering the Pi through &lt;strong&gt;both&lt;/strong&gt; Type-C and GPIO only to allow it to run the test on the SSD without power failure.&lt;/p&gt;
				&lt;p&gt;The power is a real issue this time, but putting it aside, let’s look at the results:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fio &lt;span class=&quot;nt&quot;&gt;--loops&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;5 &lt;span class=&quot;nt&quot;&gt;--size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1g &lt;span class=&quot;nt&quot;&gt;--filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;fiotest.tmp &lt;span class=&quot;nt&quot;&gt;--stonewall&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--ioengine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;libaio &lt;span class=&quot;nt&quot;&gt;--direct&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1 &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;SeqRead &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1m &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;SeqWrite &lt;span class=&quot;nt&quot;&gt;--bs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;1m &lt;span class=&quot;nt&quot;&gt;--rw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;write
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/rpi4/chart/fio-usb.png&quot; alt=&quot;FIO USB test result chart&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;That’s impressive! The ever-upgraded USB 3.0 ports, even if not running at its top speed, is an exceptional lead over previous generations of Raspberry Pi. But before enjoying the turbo speed of the new USB ports, let’s emphasize again that you need to take special care for your USB peripherals, especially those requiring just a little bit more power than others, like hard drives and SSDs. Rest assured, if the power issue is properly taken care of, utilizing these two ultra-speed USB ports would be a great benefit to your Pi-based NAS setup or whatever storage extension.&lt;/p&gt;
				&lt;h2 id=&quot;bottom-line&quot;&gt;Bottom line&lt;/h2&gt;
				&lt;p&gt;Seen the marginal improvement from Raspberry Pi 3 B to 3 B+, the new Pi 4 is probably a banquet to most Pi enthusiasts. With the price remaining the same, the Pi 4 is a must-buy for everyone, even if you already have a Pi 3 B+. While there are downsides in power supply and cooling, they aren’t much of a deal if you don’t attach too many peripherals or put the Pi at constant high load.&lt;/p&gt;</content><author><name>iBug</name></author><category term="raspberry-pi" /><category term="review" /><category term="benchmark" /><summary type="html">Lately I’ve finally received my Raspberry Pi 4 (4 GB model), and I couldn’t resist the temptation to give it a try and see all the improvements that’s been reported for months.</summary></entry><entry><title type="html">My speech at Microsoft Summer Camp 2019</title><link href="https://ibugone.com/blog/2019/08/speech-at-msc-2019/" rel="alternate" type="text/html" title="My speech at Microsoft Summer Camp 2019" /><published>2019-08-14T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/08/speech-at-msc-2019</id><content type="html" xml:base="https://ibugone.com/blog/2019/08/speech-at-msc-2019/">&lt;p&gt;&lt;em&gt;This is a translated version from &lt;a href=&quot;/p/24-cn&quot;&gt;the Chinese (original) script&lt;/a&gt;. The slideshow can be acquired &lt;a href=&quot;https://github.com/iBug/Archive/releases/download/Release/iBug-Handout.pdf&quot;&gt;here&lt;/a&gt;. For comments, please head to &lt;a href=&quot;/p/24&quot;&gt;the Chinese version&lt;/a&gt; of this post.&lt;/em&gt;&lt;/p&gt;
				&lt;p&gt;Hello everyone, I’m iBug from the University of Science and Technology of China. Today I’ll show you my experiences and tips in participating in open-source projects.&lt;/p&gt;
				&lt;h2 id=&quot;1-what-is-open-source-software&quot;&gt;1. What is Open-Source Software?&lt;/h2&gt;
				&lt;p&gt;Open-Source Software (OSS) is a classification of computer software whose source code is freely available. Open-source software always has a license attached to it, which defines the usage of its source code. A few common OSS licenses are GNU General Public License, MIT License, Apache 2.0 License and the BSD License. Different licenses pose different requirements to users of the source code. For example, GNU GPL requires that any derived work be licensed under the same terms, while MIT License is more permissive on that. Meanwhile, the public availability of the source code enables everyone to participate and commit their contribution.&lt;/p&gt;
				&lt;p&gt;The original incentive of open-source software was to share knowledge. Software design and programming skills are both knowledge, so the ancestors share them by sharing source code. In an open-source model, every user is part of the community. Everyone can join the development and maintenance work, or help test and audit the code, or chime in to the discussions. That’s how open-source software forms its distinctive collaboration model, and its adequate documentations, tutorials as well as discussions provides abundant information to whoever wants to take a part.&lt;/p&gt;
				&lt;p&gt;Then, why do people choose open-source software?&lt;/p&gt;
				&lt;p&gt;On one hand, open-source software is well-audited. Contrary to proprietary software, open-source ones are not audited by a closed group, but rather anyone interested. Anyone can audit the code of any single open-source software, which grants open-source software with its unique transparency. Meanwhile, help from people with experiences in security also adds to the overall security of the software.&lt;/p&gt;
				&lt;p&gt;On the other hand, every open-source software has a surrounding community. The persistence of the community around open-source software makes it perpetual and less likely abandoned. In addition, the variety of people in the community makes every part of the software well-maintained. Besides, the open availability of the source code enables the obtaining of a running software by compiling from source, which brings down the total cost of using it. (It isn’t unconditionally true, though, for example NGINX sells a “premium version” of the software, NGINX Plus, for a fee.)&lt;/p&gt;
				&lt;p&gt;Here’s a collection of open-source software that many people recognizes, including TensorFlow ML framework, Windows Calculator, LibreOffice office suite, as well as Debian GNU/Linux operating system. It’s apparent that open-source software exists throughout our daily life and work.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/msc2019/s7.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;h2 id=&quot;2-my-experiences-in-participating-in-open-source-projects&quot;&gt;2. My experiences in participating in open-source projects&lt;/h2&gt;
				&lt;p&gt;&lt;a href=&quot;https://github.com/iBug&quot;&gt;This is my GitHub profile page&lt;/a&gt;. The 6 pinned repositories are:&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;TetrisAI: A console tetris game written in C, with a built-in AI playing mode&lt;/li&gt;
				&lt;li&gt;SmokeDetector: This one will be discussed later&lt;/li&gt;
				&lt;li&gt;PyReversi: A GUI reversi game developed with Python and PyQt5. Also has built-in AI to provide a “human vs computer” mode&lt;/li&gt;
				&lt;li&gt;CGadgets and vbsGadgets: As suggested by their names, they’re “gadgets” written in C and VBScript&lt;/li&gt;
				&lt;li&gt;OJSangbox: My work from the course &lt;em&gt;Research for newbies&lt;/em&gt;, a sandbox implementation for online judgers using Linux technologies like chroot and rlimits.&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;&lt;a href=&quot;https://stackoverflow.com/users/5958455/ibug&quot;&gt;This is my Stack Overflow profile&lt;/a&gt;. I occasionally participate in the regular Q &amp;amp; A activities on Stack Overflow. So far I have asked 100+ questions and answered 800+, and accrued an aggregate reputation of more then 22.6k. My top few tags include &lt;code class=&quot;highlighter-rouge&quot;&gt;c++&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;c&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;python&lt;/code&gt;.&lt;/p&gt;
				&lt;h3 id=&quot;my-first-participation-in-an-open-source-project&quot;&gt;My first participation in an open-source project&lt;/h3&gt;
				&lt;p&gt;My first experience took place at &lt;a href=&quot;https://github.com/markondej/fm_transmitter&quot;&gt;markondej/fm_transmitter&lt;/a&gt;. I was trying to set up my own FM radio station and loop music, when I noticed that the “repeat” command-line option wasn’t working. I confirmed that there was nothing wrong with my Pi and the Raspbian OS on it, so I took a look at the code. It wasn’t hard for me to spot a missing negation in a condition check, so I patched it myself, compiled the code again and verified that my patch was working correctly.&lt;/p&gt;
				&lt;p&gt;My roommate was right beside me then, and came to help me when he saw me. Under his guidance, I forked the upstream repository, pushed my local changes up, and opened &lt;a href=&quot;https://github.com/markondej/fm_transmitter/pull/61&quot;&gt;my first pull request&lt;/a&gt;. Two days later, the author replied “Thanks for your help” and merged my PR.&lt;/p&gt;
				&lt;h3 id=&quot;my-primary-participation-in-another-open-source-project&quot;&gt;My primary participation in another open-source project&lt;/h3&gt;
				&lt;p&gt;&lt;img src=&quot;/image/msc2019/s7.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Look at the above image again, I anticipate that the icon at bottom-right is the least known one. It’s the logo of the organization &lt;a href=&quot;https://charcoal-se.org&quot;&gt;Charcoal-SE&lt;/a&gt;, whose primary project is &lt;a href=&quot;https://github.com/Charcoal-SE/SmokeDetector&quot;&gt;SmokeDetector&lt;/a&gt;, a headless chat bot that helps the Stack Exchange Network fight off spam.&lt;/p&gt;
				&lt;p&gt;The bot came into my attention in December 2017, and I was directed to Charcoal HQ after asking about it.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/msc2019/s14.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;And I dropped into that chat room. Every day I chat with them and watched the output from SmokeDetector, flagging spam that was reported. The routine continued to early January 2018, when someone noticed a bug with Smokey. I volunteered to take a look at it and fixed it, and fired up my first PR that changed some code (&lt;a href=&quot;https://github.com/Charcoal-SE/SmokeDetector/pull/1441&quot;&gt;#1441&lt;/a&gt;). Since then, I worked hard to study the code of SmokeDetector and continued to submit a steady stream of fixes and improvements. In March 2018, they added me to their &lt;a href=&quot;https://charcoal-se.org/people#devs&quot;&gt;list of developers&lt;/a&gt;, and in June, I was granted direct push access to the repository, indicating that I had been trusted for my proficiency in handling the project.&lt;/p&gt;
				&lt;p&gt;From SmokeDetector, I started the expansion of my contribution, and sought out for other interesting projects that I could give a hand to. One of them was &lt;a href=&quot;https://github.com/Charcoal-SE/metasmoke&quot;&gt;metasmoke&lt;/a&gt;, a web dashboard for SmokeDetector, which is a Rails-based web application itself. Another one was &lt;a href=&quot;https://charcoal-se.org&quot;&gt;Charcoal website&lt;/a&gt;, hosted on GitHub Pages and built with Jekyll. With what I learned from working on Charcoal website, I built my own website with Jekyll too, and submitted a PR to &lt;a href=&quot;https://github.com/pages-themes/cayman-theme&quot;&gt;the theme&lt;/a&gt; that I started off with.&lt;/p&gt;
				&lt;h3 id=&quot;other-contributions-ive-made&quot;&gt;Other contributions I’ve made&lt;/h3&gt;
				&lt;p&gt;In addition to code patches, I also opened a series of decent issues, name a few:&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;Magisk, a popular root framework for Android. I submitted &lt;a href=&quot;https://github.com/topjohnwu/Magisk/issue/512&quot;&gt;a suggestion&lt;/a&gt; to improve its install script, which was accepted later. (#512)&lt;/li&gt;
				&lt;li&gt;wtfpython, a collection of interesting Python constructs. I pointed out a mistake in the document (#81)&lt;/li&gt;
				&lt;li&gt;BaiduPCS-Go, a command-line client for Baidu Net Disk. I reported a bug. (#402)&lt;/li&gt;
				&lt;li&gt;I also opened a few trivial issues in repositories I’m familiar with, so that more people could learn them by participating in &lt;a href=&quot;https://hacktoberfest.digitalocean.com&quot;&gt;Hacktoberfest&lt;/a&gt;.&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;In addition, I’m also an active participant in various discussions, as well as Stack Overflow. I enjoy helping others with my knowledge.&lt;/p&gt;
				&lt;p&gt;My personal top ★ repo is &lt;a href=&quot;https://github.com/iBug/pac&quot;&gt;pac&lt;/a&gt;, which originated from &lt;a href=&quot;https://github.com/shadowsocks/shadowsocks-windows/issues/1873#issuecomment-416293495&quot;&gt;a discussion&lt;/a&gt; on another repository. People had a strong need for a functionality, which was implementable just with a PAC script, so I wrote one and shared it with the &lt;em&gt;pac&lt;/em&gt; repo, which has accumulated a total of 24 stars by the time of writing this article. There’s one thing we can know for sure, that its star amount wasn’t for its complexity or use of high-tech, but rather its usefulness to passers-by. The issues section has also received a few questions, all of which has been answered by me.&lt;/p&gt;
				&lt;h3 id=&quot;what-ive-learned&quot;&gt;What I’ve learned&lt;/h3&gt;
				&lt;p&gt;I’d say pretty much the primary thing I’ve learned from those experiences is teamwork. Teamwork is very inclusive and involves the use of Git Version Control System (VCS), a consistent coding style and documentation style, as well as the meaning and usage of a Continuous Integration system, and most importantly, the skills of communication.&lt;/p&gt;
				&lt;h2 id=&quot;3-getting-involved-by-yourself&quot;&gt;3. Getting involved by yourself&lt;/h2&gt;
				&lt;p&gt;Before chiming in, you should understand one point that an open-source project is a &lt;em&gt;project&lt;/em&gt; and thus, you have flexible ways of contribution.&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;
				&lt;p&gt;For software, the most intuitive contribution is to submit code patches, for example bug fixes, enhancements and test suites.&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;Besides, it’s also a valuable kind of contribution to help improve documentations and tutorials&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;Meanwhile, translating documents into other languages enables more people to participate.&lt;/p&gt;
				&lt;p&gt;For example, &lt;a href=&quot;https://www.transifex.com/&quot;&gt;Transifex&lt;/a&gt; is a commonly used translation collaboration platform, and it powers many well-known projects like Disqus and SoundCloud.&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;Finally, if you’re not interested in all of above, you still have the option of contributing supplementary information, like Q &amp;amp; A and bug reports.&lt;/p&gt;
				&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;So then, what are we going to reap for ourselves?&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;
				&lt;p&gt;The most direct consequence is that you gained hand-on experiences working on a real-life project.&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;You also practiced your existing skills and learned new ones.&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;You acquired important knowledge and wisdom.&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;You can easily show off your hard work on open-source projects.&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;You can stand out from the crowd when applying for opportunities. Apparently, your HR / curator / mentor will more likely give you the offer when they can actually see your work.&lt;/p&gt;
				&lt;p&gt;An immediate example is my chance of speaking here, which owes a lot to the fact that my open-source achievements can be easily seen and verified by the event host.&lt;/p&gt;
				&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;Looks rather attractive, right? Then it’s time to set yourself up.&lt;/p&gt;
				&lt;h3 id=&quot;discover-your-abilities&quot;&gt;Discover your abilities&lt;/h3&gt;
				&lt;p&gt;The first thing to decide is what you excel at. Say for example, if you’re good at turning ideas into code, or if you’re competent in discovering leak holes, or if you’re innovative at designing, and so on. Specific abilities help you excel at specific tasks.&lt;/p&gt;
				&lt;h3 id=&quot;find-your-interest&quot;&gt;Find your interest&lt;/h3&gt;
				&lt;p&gt;Then you should find a project of your interest. There are a few ways to search for them, listing a few for example:&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;A piece of software that you use on a daily basis&lt;/li&gt;
				&lt;li&gt;An interesting project that you come across, like the trio on the right side of GitHub dashboard&lt;/li&gt;
				&lt;li&gt;
				&lt;p&gt;Random events that advocate open-source projects like &lt;a href=&quot;https://hacktoberfest.digitalocean.com&quot;&gt;Hacktoberfest&lt;/a&gt;, or another long-running one &lt;a href=&quot;https://up-for-grabs.net/&quot;&gt;Up For Grabs&lt;/a&gt;&lt;/p&gt;
				&lt;/li&gt;
				&lt;li&gt;Finally, an innovative idea that could start a new project on its own&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;If you decide to join an existing project, there are some preliminary checks that I advise you to perform.&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;First and foremost, it’s mandatory that an open-source project contains a &lt;code class=&quot;highlighter-rouge&quot;&gt;LICENSE&lt;/code&gt;. And it adds up if it has a Code of Conduct as well.&lt;/li&gt;
				&lt;li&gt;You should also judge the activity of the project, like the time of the last commit, as well as how often project maintainers commit.&lt;/li&gt;
				&lt;li&gt;It’s a big bonus if the project has an active community, who can generate a lot of Issues and Pull Requests, both of which are good indicators of project activity.&lt;/li&gt;
				&lt;li&gt;Finally, a friendly atmosphere makes discussion more comfortable and constructive.&lt;/li&gt;
				&lt;/ul&gt;
				&lt;h3 id=&quot;effective-communication&quot;&gt;Effective communication&lt;/h3&gt;
				&lt;p&gt;The most common thing that happens throughout your activity in a project is communicating with others. It’s often worth noting for the sake of the effectiveness of your communication that:&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;You’re expected to do researches beforehand by yourself. You should probably avoid asking “how to write code for this”, and at the very least, “I wrote this code and it’s wrong” is a better question.&lt;/li&gt;
				&lt;li&gt;Should you really need to ask a question like “I wrote this code and it’s wrong”, you must provide enough context and (probably) code for others to identify the problem. Similarly, whatever discussion you’re starting, ensure you’ve enabled others to replicate what you’re describing.&lt;/li&gt;
				&lt;li&gt;Keep the discussion straight and on-topic. It’s very likely that no one is interested in that you wrote the code in Starbucks after an afternoon’s work at the port carrying bricks.&lt;/li&gt;
				&lt;li&gt;For public projects, keep the discussion public as well, unless there are other reasons not to, for example reporting security issues or misbehavior of other community members.&lt;/li&gt;
				&lt;li&gt;Respect others should their opinions differ.&lt;/li&gt;
				&lt;/ul&gt;
				&lt;h3 id=&quot;after-submitting-your-contribution&quot;&gt;After submitting your contribution&lt;/h3&gt;
				&lt;p&gt;It’s time for you to wait for project maintainers to review your contribution and take further actions. There are a few outcomes here.&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;No one pays any attention to it and your Issue or PR just hangs. Maybe you should simply wait for longer, or perhaps you should have checked the project for recent activity.&lt;/li&gt;
				&lt;li&gt;If anyone suggests improvement, it means that others have taken time to review your contribution. You should respect them and respond in time.&lt;/li&gt;
				&lt;li&gt;Sometimes the maintainers or the community doesn’t accept your contribution. Don’t panic, see what others think and say, collect them as your own experiences.&lt;/li&gt;
				&lt;li&gt;If your contribution gets accepted, then &lt;strong&gt;Congratulations&lt;/strong&gt;!&lt;/li&gt;
				&lt;/ul&gt;
				&lt;h2 id=&quot;epilogue&quot;&gt;Epilogue&lt;/h2&gt;
				&lt;p&gt;Whether you’re new to open-source projects, or experienced in the field, I hope you can go ahead and carry forward the idea of open-source.&lt;/p&gt;
				&lt;h2 id=&quot;more-reading&quot;&gt;More reading&lt;/h2&gt;
				&lt;ul&gt;
				&lt;li&gt;&lt;a href=&quot;https://dev.to/kerryja/getting-started-with-open-source-3o23&quot;&gt;https://dev.to/kerryja/getting-started-with-open-source-3o23&lt;/a&gt;&lt;/li&gt;
				&lt;li&gt;&lt;a href=&quot;https://opensource.guide/&quot;&gt;https://opensource.guide/&lt;/a&gt;&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;For comments, please head to &lt;a href=&quot;/p/24&quot;&gt;the Chinese version&lt;/a&gt; of this post.&lt;/p&gt;</content><author><name>iBug</name></author><category term="speech" /><summary type="html">This is a translated version from the Chinese (original) script. The slideshow can be acquired here. For comments, please head to the Chinese version of this post.</summary></entry><entry><title type="html">Creating templated Systemd services</title><link href="https://ibugone.com/blog/2019/07/systemd-service-template/" rel="alternate" type="text/html" title="Creating templated Systemd services" /><published>2019-07-16T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/07/systemd-service-template</id><content type="html" xml:base="https://ibugone.com/blog/2019/07/systemd-service-template/">&lt;p&gt;Last time I wrote an article about &lt;a href=&quot;/p/14&quot;&gt;NAT traversal using FRP&lt;/a&gt;, which has been my personal solution for exposing SSH access of machines behind NAT to the internet for a long time.&lt;/p&gt;
				&lt;p&gt;As time goes by, I get more devices behind NAT and more VPS hosts providing FRP access, and the need for connecting one device with multiple FRP hosts arises. Surely, one solution would be writing multiple config files and Systemd service files for each instance of &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc&lt;/code&gt;, which would just run perfectly.&lt;/p&gt;
				&lt;h2 id=&quot;writing-multiple-systemd-service-files&quot;&gt;Writing multiple Systemd service files&lt;/h2&gt;
				&lt;p&gt;Let’s start this with one &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc.service&lt;/code&gt; file that I wrote and am using:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
				Description=FRP Client Service
				After=network.target
				StartLimitIntervalSec=0
				[Service]
				Type=simple
				Restart=always
				RestartSec=1
				User=root
				ExecStart=/usr/local/bin/frpc -c /etc/frpc.ini
				[Install]
				WantedBy=multi-user.target
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Now I want to add another &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc&lt;/code&gt; instance with an alternate configuration, I could just copy the above file, modify the &lt;code class=&quot;highlighter-rouge&quot;&gt;ExecStart&lt;/code&gt; line, and save it as another file.&lt;/p&gt;
				&lt;p&gt;However, that’s undoubtably a suboptimal solution, especially given that Systemd service files can use “template variables”&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Having too many &lt;em&gt;otherwise&lt;/em&gt; identical service configuration files is particularly prone to making a mess. With “template variables”, you can simplify all this job into one single file&lt;/p&gt;
				&lt;h2 id=&quot;using-systemd-service-instance-variables&quot;&gt;Using Systemd service instance variables&lt;/h2&gt;
				&lt;p&gt;Among all “instance variables”, the most commonly used one is “instance name” &lt;code class=&quot;highlighter-rouge&quot;&gt;%i&lt;/code&gt;. You’ll just replace the variable part with &lt;code class=&quot;highlighter-rouge&quot;&gt;%i&lt;/code&gt;, and in my case, it’s the config file name for &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;Instead of putting &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc&lt;/code&gt; config files directly under &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc&lt;/code&gt;, the first thing I did is making a directory &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/frpc&lt;/code&gt; for all of them. Then I put the “default” one into the directory as &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/frpc/default.ini&lt;/code&gt;, and re-written the service file, utilizing instance variables, as this:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Unit]
				Description=FRP Client Service (%i)
				After=network.target
				StartLimitIntervalSec=0
				[Service]
				Type=simple
				Restart=always
				RestartSec=1
				User=root
				ExecStart=/usr/local/bin/frpc -c /etc/%i.ini
				[Install]
				WantedBy=multi-user.target
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Notice the two appearances of &lt;code class=&quot;highlighter-rouge&quot;&gt;%i&lt;/code&gt; here: The first one in unit description, and the second one on the line &lt;code class=&quot;highlighter-rouge&quot;&gt;ExecStart&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;There’s also another thing to note: It’s no longer applicable to name the file as &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc.service&lt;/code&gt;, but instead, &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc@.service&lt;/code&gt;. The AT sign in the file name indicates it’s a “template service”.&lt;/p&gt;
				&lt;p&gt;Now, to instantiate the &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc@&lt;/code&gt; service into instance “default” (which is also the config file name in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/frpc&lt;/code&gt;), the following commands were used to manage it:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;systemctl start frpc@default.service
				systemctl stop frpc@default.service
				systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;frpc@default.service
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;And an extra note on the &lt;code class=&quot;highlighter-rouge&quot;&gt;enable&lt;/code&gt; command: If you notice the output from &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl&lt;/code&gt;, it should read like this:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ibug@ubuntu:~&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sudo &lt;/span&gt;systemctl &lt;span class=&quot;nb&quot;&gt;enable &lt;/span&gt;frpc@example.service
				Created symlink /etc/systemd/system/multi-user.target.wants/frpc@example.service → /etc/systemd/system/frpc@.service
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;Yep, the file isn’t modified in any way, only a symlink is created.&lt;/p&gt;
				&lt;p&gt;As you can guess, the instance name &lt;code class=&quot;highlighter-rouge&quot;&gt;%i&lt;/code&gt; is substituted at the time the file is parsed. This means you can modify the service file on the go and any changes will take effect the next time you run a &lt;code class=&quot;highlighter-rouge&quot;&gt;systemctl&lt;/code&gt; command that reads the file.&lt;/p&gt;
				&lt;p&gt;And here’s the topic: For each additional &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc&lt;/code&gt; instance, the only thing to do is to place its config file under &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/frpc/something.ini&lt;/code&gt;, and the new instance can be launched at &lt;code class=&quot;highlighter-rouge&quot;&gt;frpc@something&lt;/code&gt;.&lt;/p&gt;
				&lt;p&gt;For a complete list of instance specifiers, &lt;a href=&quot;https://www.freedesktop.org/software/systemd/man/systemd.unit.html#Specifiers&quot;&gt;here&lt;/a&gt;’s a good reference. Time to get yourself some work to cleanup your messy Systemd services :)&lt;/p&gt;
				&lt;div class=&quot;footnotes&quot;&gt;
				&lt;ol&gt;
				&lt;li id=&quot;fn:1&quot;&gt;
				&lt;p&gt;It’s official name is “instance specifier”, which IMO is less intuitive. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
				&lt;/li&gt;
				&lt;/ol&gt;
				&lt;/div&gt;</content><author><name>iBug</name></author><category term="linux" /><summary type="html">Last time I wrote an article about NAT traversal using FRP, which has been my personal solution for exposing SSH access of machines behind NAT to the internet for a long time.</summary></entry><entry><title type="html">Using SSH deploy keys on CircleCI</title><link href="https://ibugone.com/blog/2019/07/circleci-ssh-delpoy-keys/" rel="alternate" type="text/html" title="Using SSH deploy keys on CircleCI" /><published>2019-07-08T00:00:00+00:00</published><updated>2019-12-09T17:48:34+00:00</updated><id>https://ibugone.com/blog/2019/07/circleci-ssh-delpoy-keys</id><content type="html" xml:base="https://ibugone.com/blog/2019/07/circleci-ssh-delpoy-keys/">&lt;p&gt;A year ago back I &lt;a href=&quot;/p/4&quot;&gt;wrote an article&lt;/a&gt; on automating build &amp;amp; deployment of GitHub Pages website with Travis CI. It’s a great CI service at first, but since &lt;a href=&quot;https://blog.travis-ci.com/2018-10-04-combining-linux-infrastructures&quot;&gt;Travis CI has completely moved away from containers&lt;/a&gt;, speed is a real issue to whoever is concerned. On the other side, CircleCI is continuing their builds with Docker-based containers, whose rapid response is a &lt;em&gt;great&lt;/em&gt; advantage against VMs with slow boot time.&lt;/p&gt;
				&lt;p&gt;Migrating the build script from Travis CI was an intuitive and easy step, but I immediately got disappointed by CircleCI’s logging: Secret environment variables get exposed in the log as long as any command or program prints them.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/circleci/token-leak.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;That’s particularly annoying because I used Personal Access Tokens to push built content back to GitHub, and this kind of straightforward leaks is a huge security issue, so I looked around for alternatives, and came up with the idea of using a deploy key with write access.&lt;/p&gt;
				&lt;p&gt;Setting up the basics wasn’t any difficult on its own for anyone with a bit experience in Linux:&lt;/p&gt;
				&lt;ul&gt;
				&lt;li&gt;Generate an SSH key pair with &lt;code class=&quot;highlighter-rouge&quot;&gt;ssh-keygen&lt;/code&gt;&lt;/li&gt;
				&lt;li&gt;Encode (or compress + encode) the private key and put it into the CI environment&lt;/li&gt;
				&lt;li&gt;Create a build script to grab key from environment and utilize it&lt;/li&gt;
				&lt;/ul&gt;
				&lt;p&gt;Once you’ve figured out the build script, everything appears straightforward:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-z&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SSH_KEY_E&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;then
				&lt;/span&gt;e_error &lt;span class=&quot;s2&quot;&gt;&quot;No SSH key found in environment.&quot;&lt;/span&gt;
				&lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1
				&lt;span class=&quot;k&quot;&gt;fi
				&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;base64&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$SSH_KEY_E&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt; | &lt;span class=&quot;nb&quot;&gt;gunzip&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; ~/.ssh/id_rsa
				&lt;span class=&quot;nb&quot;&gt;chmod &lt;/span&gt;600 ~/.ssh/id_rsa
				git clone &lt;span class=&quot;nt&quot;&gt;--depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3 &lt;span class=&quot;nt&quot;&gt;--branch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$BRANCH&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;git@github.com:&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$GH_REPO&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;.git&quot;&lt;/span&gt; _site
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;At first glance, it &lt;em&gt;should&lt;/em&gt; work without any problem. But that’s apparently only an &lt;em&gt;assumption&lt;/em&gt;, no? And if you follow the build log, you’ll immediately know when it runs into &lt;em&gt;the problem&lt;/em&gt;:&lt;/p&gt;
				&lt;div class=&quot;language-text highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ERROR: The key you are authenticating with has been marked as read only.
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;It’s particularly confusing when you’ve written your SSH private key to the correct path, set the correct permission and expecting SSH to respect your key, only to find it’s actually offering another key to GitHub and fails.&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/circleci/ssh-fail.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Digging around with debug information (set &lt;code class=&quot;highlighter-rouge&quot;&gt;GIT_SSH_COMMAND='ssh -vv'&lt;/code&gt;), I noticed this absurd thing:&lt;/p&gt;
				&lt;p&gt;&lt;img src=&quot;/image/circleci/key-not-found.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;Clearly, the aptly placed key wasn’t even found by SSH, rendering it completely unusable in status quo. I’ve even tried crafting &lt;code class=&quot;highlighter-rouge&quot;&gt;~/.ssh/config&lt;/code&gt;, but unfortunately it’s ignored as well.&lt;/p&gt;
				&lt;h3 id=&quot;solution&quot;&gt;Solution&lt;/h3&gt;
				&lt;p&gt;Just like most other CLI utilities, SSH respects command-line arguments loyally. So you would just specify the identity file there:&lt;/p&gt;
				&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;GIT_SSH_COMMAND&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ssh -i ~/.ssh/id_rsa'&lt;/span&gt;
				&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
				&lt;p&gt;&lt;img src=&quot;/image/circleci/solution.png&quot; alt=&quot;image&quot; class=&quot;block&quot; /&gt;&lt;/p&gt;
				&lt;p&gt;And I don’t even know what’s going on behind the scenes, but it just works.&lt;/p&gt;
				&lt;p&gt;Reference: &lt;a href=&quot;https://stackoverflow.com/q/55177042/5958455&quot;&gt;Stack Overflow&lt;/a&gt;&lt;/p&gt;</content><author><name>iBug</name></author><category term="development" /><category term="github-pages" /><summary type="html">A year ago back I wrote an article on automating build &amp;amp; deployment of GitHub Pages website with Travis CI. It’s a great CI service at first, but since Travis CI has completely moved away from containers, speed is a real issue to whoever is concerned. On the other side, CircleCI is continuing their builds with Docker-based containers, whose rapid response is a great advantage against VMs with slow boot time.</summary></entry></feed>