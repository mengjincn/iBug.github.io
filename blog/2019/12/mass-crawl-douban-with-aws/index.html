<!doctype html>
<!--
  Minimal Mistakes Jekyll Theme 4.17.2 by Michael Rose
  Copyright 2013-2019 Michael Rose - mademistakes.com | @mmistakes
  Free for personal and commercial use under the MIT license
  https://github.com/mmistakes/minimal-mistakes/blob/master/LICENSE
-->
<html lang="en" class="no-js">
	<head>
		<meta charset="utf-8">
		<!-- begin _includes/seo.html --><title>High-performance mass web crawling on AWS - iBug One</title>
		<meta name="description" content="The 3rd-and-last experiment of course Web Information Processing and Application required us to create a recommendation engine, and “predict” the rating (1-5 stars) for 4M user-item pairs based on the training data of 9M user-item pairs and a social network.">
		<meta name="author" content="iBug">
		<meta property="og:type" content="article">
		<meta property="og:locale" content="en_US">
		<meta property="og:site_name" content="iBug One">
		<meta property="og:title" content="High-performance mass web crawling on AWS">
		<meta property="og:url" content="https://ibugone.com/blog/2019/12/mass-crawl-douban-with-aws/">
		<meta property="og:description" content="The 3rd-and-last experiment of course Web Information Processing and Application required us to create a recommendation engine, and “predict” the rating (1-5 stars) for 4M user-item pairs based on the training data of 9M user-item pairs and a social network.">
		<meta property="og:image" content="https://ibugone.com/image/header/mountain-1.jpg">
		<meta property="article:published_time" content="2019-12-28T00:00:00+00:00">
		<meta property="article:modified_time" content="2020-01-01T18:52:23+00:00">
		<link rel="canonical" href="https://ibugone.com/blog/2019/12/mass-crawl-douban-with-aws/">
		<script type="application/ld+json">
			{
			  "@context": "https://schema.org",
			
			    "@type": "Person",
			    "name": "iBug",
			    "url": "https://ibugone.com/"
			
			}
		</script>
		<meta name="google-site-verification" content="5_jn7a-vZslUtLJO-BkY-cPDGgah5JP49RGgeOBmYSk" />
		<!-- end _includes/seo.html -->
		<link href="/feed.xml" type="application/atom+xml" rel="alternate" title="iBug One Feed">
		<!-- https://t.co/dKP3o1e -->
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<script>
			document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
		</script>
		<!-- For all browsers -->
		<link rel="stylesheet" href="/assets/css/main.css">
		<!--[if IE]>
			<style>
				/* old IE unsupported flexbox fixes */
				.greedy-nav .site-title {
				  padding-right: 3em;
				}
				.greedy-nav button {
				  position: absolute;
				  top: 0;
				  right: 0;
				  height: 100%;
				}
			</style>
		<![endif]-->
		<link rel="shortcut icon" type="image/png" href="/assets/favicon.png">
		<meta name="theme-color" content="#EDEDED">
		<script type="text/javascript">
			const funcOnPageLoad = () => document.querySelector("body").classList.add("loaded");
			if (document.readyState !== "loading")
				setTimeout(funcOnPageLoad, 500);
			else
				document.addEventListener('DOMContentLoaded', funcOnPageLoad);
		</script>
		<script type="text/javascript" async src="/assets/js/love.js"></script>
		<!--
	Minimal Mistakes layout: single
	Page Path: _posts/2019-12-28-mass-crawl-douban-with-aws.md
	Page Type: 
-->
	</head>
	<body class="layout--single">
		<nav class="skip-links">
			<h2 class="screen-reader-text">Skip links</h2>
			<ul>
				<li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
				<li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
				<li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
			</ul>
		</nav>
		<!--[if lt IE 9]>
			<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
		<![endif]-->
		<div class="masthead">
			<div class="masthead__inner-wrap">
				<div class="masthead__menu">
					<nav id="site-nav" class="greedy-nav">
						<a class="site-logo" href="/"><img src="/assets/favicon.png" alt=""></a>
						<a class="site-title" href="/">
							iBug
						</a>
						<ul class="visible-links">
							<li class="masthead__menu-item">
								<a href="/about/" >About</a>
							</li>
							<li class="masthead__menu-item">
								<a href="/blog/" >Blog</a>
							</li>
							<li class="masthead__menu-item">
								<a href="/projects/" >Projects</a>
							</li>
							<li class="masthead__menu-item">
								<a href="https://github.com/iBug" >GitHub <i class="fa fas fa-xs fa-external-link-alt"></i></a>
							</li>
							<li class="masthead__menu-item">
								<a href="/cn/" >中文内容</a>
							</li>
						</ul>
						<button class="search__toggle" type="button">
							<span class="visually-hidden">Toggle search</span>
							<svg class="icon" width="16" height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 15.99 16">
								<path d="M15.5,13.12L13.19,10.8a1.69,1.69,0,0,0-1.28-.55l-0.06-.06A6.5,6.5,0,0,0,5.77,0,6.5,6.5,0,0,0,2.46,11.59a6.47,6.47,0,0,0,7.74.26l0.05,0.05a1.65,1.65,0,0,0,.5,1.24l2.38,2.38A1.68,1.68,0,0,0,15.5,13.12ZM6.4,2A4.41,4.41,0,1,1,2,6.4,4.43,4.43,0,0,1,6.4,2Z" transform="translate(-.01)"></path>
							</svg>
						</button>
						<button class="greedy-nav__toggle hidden" type="button">
							<span class="visually-hidden">Toggle menu</span>
							<div class="navicon"></div>
						</button>
						<ul class="hidden-links hidden"></ul>
					</nav>
				</div>
			</div>
		</div>
		<div class="initial-content">
			<div class="page__hero--overlay"
  style=" background-image: url('/image/header/mountain-1.jpg');"
>
				<div class="wrapper">
					<h1 id="page-title" class="page__title" itemprop="headline">
						High-performance mass web crawling on AWS
					</h1>
					<p class="page__meta"><i class="far fa-calendar-alt" aria-hidden="true"></i> December 28, 2019</p>
				</div>
			</div>
			<div id="main" role="main">
				<div class="sidebar sticky">
					<div itemscope itemtype="https://schema.org/Person">
						<div class="author__avatar">
							<img src="/image/avatar.png" alt="iBug" itemprop="image">
						</div>
						<div class="author__content">
							<h3 class="author__name" itemprop="name">iBug</h3>
							<div class="author__bio" itemprop="description">
								<p>Developer, System Administrator, Geek</p>
							</div>
						</div>
						<div class="author__urls-wrapper">
							<button class="btn btn--inverse">Follow</button>
							<ul class="author__urls social-icons">
								<li><a href="mailto:%69@ibugone.com" rel="nofollow noopener noreferrer"><i class="fas fa-fw fa-envelope-square" aria-hidden="true"></i> Email</a></li>
								<li><a href="https://stackoverflow.com/users/5958455/ibug" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-stack-overflow" aria-hidden="true"></i> Stack Overflow</a></li>
								<li><a href="https://github.com/iBug" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
								<li><a href="https://steamcommunity.com/id/ibugone" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-steam" aria-hidden="true"></i> Steam</a></li>
								<!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
							</ul>
						</div>
					</div>
				</div>
				<article class="page" itemscope itemtype="https://schema.org/CreativeWork">
					<meta itemprop="headline" content="High-performance mass web crawling on AWS">
					<meta itemprop="description" content="The 3rd-and-last experiment of course Web Information Processing and Application required us to create a recommendation engine, and “predict” the rating (1-5 stars) for 4M user-item pairs based on the training data of 9M user-item pairs and a social network.">
					<meta itemprop="datePublished" content="December 28, 2019">
					<meta itemprop="dateModified" content="January 01, 2020">
					<div class="page__inner-wrap">
						<section class="page__content" itemprop="text">
							<aside class="sidebar__right sticky">
								<nav class="toc">
									<header>
										<h4 class="nav__title"><i class="fas fa-file-alt"></i> On this page</h4>
									</header>
									<ul class="toc__menu">
										<li><a href="#part-1-scrapy-and-scrapinghub">Part 1: Scrapy and ScrapingHub</a></li>
										<li><a href="#part-2-expansion-onto-aws-distributed-crawling-with-centralized-management">Part 2: Expansion onto AWS, distributed crawling with centralized management</a>
											<ul>
												<li><a href="#the-central-manager-server">The central manager server</a></li>
												<li><a href="#distributed-crawler-clients">Distributed crawler clients</a></li>
												<li><a href="#results">Results</a></li>
											</ul>
										</li>
										<li><a href="#part-3-redesigned-management-architecture-fine-grained-control-more-robust-and-faster">Part 3: Redesigned management architecture, fine-grained control, more robust and faster</a></li>
									</ul>
								</nav>
							</aside>
							<p>The 3rd-and-last experiment of course <em>Web Information Processing</em> and Application required us to create a recommendation engine, and “predict” the rating (1-5 stars) for 4M user-item pairs based on the training data of 9M user-item pairs and a social network.</p>
							<p>The interesting part is, all user and rating data are real, i.e. unmasked. This makes it possible to, instead of playing nicely by doing data analysis, crawl the target data directly, bypassing the aim of the experiment to learn about recommendation systems, which is exactly the way I chose and I’m going to describe in this article.</p>
							<p>To make things challenging, the target website, <a href="https://www.douban.com/">Douban</a>, has a moderate level of anti-spider techniques in place. This makes it impossible to just submit a truckload of requests hoping to retrieve all data desired, but more advanced technologies and cleverer tactics are mandatory before pulling it off.</p>
							<h2 id="part-1-scrapy-and-scrapinghub">Part 1: Scrapy and ScrapingHub</h2>
							<p>Previously I’ve done crawlers using <a href="https://2.python-requests.org/">requests</a> + <a href="https://www.crummy.com/software/BeautifulSoup/">Beautiful Soup</a>, but this time under suggestions from my roommate, I decided to try it out with <a href="https://scrapy.org/">Scrapy</a>, a said-to-be-great web crawling framework.</p>
							<p>Scrapy is a framework extremely easy to start with. I followed the guide on Scrapy’s website and wrote less than 30 lines of Python (<a href="https://github.com/iBug/douban-spider/commit/8aead82">commit</a>), and the first version of my spider was ready to go.</p>
							<p>It didn’t take too long before I picked up on Douban’s anti-spider techniques. My server’s IP was banned (fortunately, only temporarily) and all requests to Douban were getting 403 responses.</p>
							<p>I fortuitously recalled that GitHub Student Pack provides an offer from <a href="https://scrapinghub.com/">ScrapingHub</a>, the company behind Scrapy, containing one scraper unit, for free forever. Following their guide on deployment, I asked my teammate to modify my spider to adopt Scrapy’s project layout (<a href="https://github.com/iBug/douban-spider/compare/cecbcfb..8eb1ff1">commit</a>), redeemed the Student Pack offer, and deployed my first scraper project onto ScrapingHub cloud.</p>
							<figure>
								<img src="/image/scrapinghub.png" alt="ScrapingHub results" />
								<figcaption>
									My job history on ScrapingHub, all of which are for this experiment
								</figcaption>
							</figure>
							<p>ScrapingHub has forced AutoThrottle enabled for all jobs, so my first SH job survived for longer before it started receiving 403 responses. Looking at the stats, the job maintained its position for about 40 minutes, before signals of having its IP banned emerged. I updated the scraper a few times to include detections for more variations of indications of an IP ban, but never made it over an hour. And because I only attempted to avoid the IP ban by throttling and detecting, the actual “targets” contained in the code remained the same, which accounted for high duplication in crawled results in the first few runs, which in turn led to a quick drop in the increase of the submitted result (of this course experiment).</p>
							<p>Recalling that I had spare promotional credits from AWS Educate, I came up with the idea of utilizing the large IP pool of AWS, which has another advantage of the ease to swap out a banned one.</p>
							<h2 id="part-2-expansion-onto-aws-distributed-crawling-with-centralized-management">Part 2: Expansion onto AWS, distributed crawling with centralized management</h2>
							<p>The high duplication rate of results from the first few runs on ScrapingHub was alarming: I knew that I wouldn’t make any real success if I didn’t build a centralized job dispatcher and data collector, so the first thing before moving onto AWS is to create a control center.</p>
							<h3 id="the-central-manager-server">The central manager server</h3>
							<p>I picked my favorite quickstarter framework Flask, implemented three simple interfaces <code class="highlighter-rouge">get job</code>, <code class="highlighter-rouge">update job</code> and <code class="highlighter-rouge">add result</code>. To make things absolutely simple yet reliable, I picked SQLite as database backend because it’s easy to setup and query (<code class="highlighter-rouge">sqlite3</code> CLI is ready for use). I designed a “job pool” with push-pop architecture, where each job record is a to-be-crawled URL, and is deleted from the pool once it’s requested. The spider then crawls the page, send results back to the control center, as well as the “Next Page” link in the page back into the job pool if there is one. It didn’t even take a lot of effort to work this out (<a href="https://github.com/iBug/douban-spider/blob/5da2c80441aee5dd1ba0ee38f28d5edde393635b/server.py">code</a>). The initial content in the “job pool” is Page 1 of all 20000 users, imported from experiment materials manually.</p>
							<p>Deployment is just as easy. I wrapped the server up in a Docker container, put it on my primary server on Amazon Lightsail (2 GB instance, has some other stuff running already), configured Nginx and added a DNS record on Cloudflare. Then I started the spider on my workstation and send a few initial requests, to test if everything proceeds as expected. After cleaning a few obvious bugs out of the code base, I started configuring a spider client.</p>
							<h3 id="distributed-crawler-clients">Distributed crawler clients</h3>
							<p>Because I planned to spawn a large amount of clients, I want to lower their cost (I have only $100 credits and can’t spend overbudget), so I started off with t3.nano instances as they offered twice the CPU power and slightly less expense over the previous-generation t2.nano. Configuring the environment wasn’t any difficult, as all that was needed was a deploy key and dependency packages. The former can be generated locally and have the public part uploaded to GitHub before copying the private part onto the spider server, and the latter is as easy as running <code class="highlighter-rouge">pip install</code>.</p>
							<p>To make further deployment easier, I created a systemd service for the spider job, and added <code class="highlighter-rouge">git pull</code> before starting, so I only need to restart all servers and they’d pull in latest changes automatically. This is the service file that I wrote for this job.</p>
							<div class="language-ini highlighter-rouge">
								<div class="highlight">
									<pre class="highlight"><code><span class="nn">[Unit]</span>
<span class="py">Description</span><span class="p">=</span><span class="s">Douban Spider</span>
<span class="py">After</span><span class="p">=</span><span class="s">multi-user.target</span>
<span class="py">StartLimitIntervalSec</span><span class="p">=</span><span class="s">0</span>

<span class="nn">[Service]</span>
<span class="py">Type</span><span class="p">=</span><span class="s">simple</span>
<span class="py">Restart</span><span class="p">=</span><span class="s">always</span>
<span class="py">RestartSec</span><span class="p">=</span><span class="s">1</span>
<span class="py">ExecStartPre</span><span class="p">=</span><span class="s">/usr/bin/git -C /root/douban-spider pull</span>
<span class="py">ExecStart</span><span class="p">=</span><span class="s">/usr/local/bin/scrapy crawl doubanspider</span>
<span class="py">WorkingDirectory</span><span class="p">=</span><span class="s">/root/douban-spider/</span>
<span class="py">TimeoutSec</span><span class="p">=</span><span class="s">5</span>

<span class="nn">[Install]</span>
<span class="py">WantedBy</span><span class="p">=</span><span class="s">multi-user.target</span>
</code></pre>
								</div>
							</div>
							<p>I ran <code class="highlighter-rouge">systemctl daemon-reload</code> to let systemd reload and be aware of my new service unit. I then started the spider with <code class="highlighter-rouge">systemctl start spider.service</code> and followed <code class="highlighter-rouge">journalctl -ef</code> to check if the spider is running properly. To make the spider start automatically on boot, I ran <code class="highlighter-rouge">systemctl enable spider.service</code>.</p>
							<p>As I was going to work around Douban’s IP limitations, I let the spider shut down itself when it discovers the IP ban (<a href="https://github.com/iBug/douban-spider/commit/d4b7e20">commit</a>). This way by looking at the number of running instances on EC2 dashboard, I can determine how many IPs have been banned, and can get new IPs by starting them up again (rebooting doesn’t change instance IP, must stop completely and then start again).</p>
							<p>I then rebooted the server once, and checked again to be 100% sure that everything is working as expected. Confirming that, I shut down the server and took a snapshot of it.</p>
							<figure>
								<img src="/image/spider-aws/snapshot.png" alt="Snapshot of a spider instance" />
								<figcaption>
									Information panel of a snapshot taken from a properly configured spider instance, ready for deployment
								</figcaption>
							</figure>
							<p>And as well, before launching new instances from this snapshot, an AMI (Amazon Machine Image) has to be registered based off of it, so I did one as well.</p>
							<figure>
								<img src="/image/spider-aws/ami.png" alt="AMI registered from the above snapshot" />
								<figcaption>
									Information panel of an Amazon Machine Image registered from the above snapshot
								</figcaption>
							</figure>
							<p>I Googled about AWS service limits, and acknowledged that there was a “20 instances per region” limit on EC2. So I attempted to create 20 t3.nano instances from the AMI, but was informed that the launch request would fail for exceeding another resource limit of 32 vCPUs. OK, that was fine, I decided to launch 12 instance first, and launch the remaining 8 with one vCPU disabled, resulting in a total of 32 vCPUs. Unfortunately it failed again for unknown reasons, though I managed to figure it out that disabled vCPUs still count, so I ended up creating t2.nano instances for the rest of them.</p>
							<p>It wasn’t necessarily something bad, however, as T2 series of instances can burst to 100% CPU for 30 minutes after startup, which should cover most of its lifetime before it gets banned.</p>
							<div class="notice">
								<p>I have forgotten how I realized this, but the currect actuality is that there’s no more “instance limit”, but only a limit on total vCPU count. This is still effectively a limit on the number of instances you can have simultaneously, though you get to keep less if you run multi-core instances.</p>
							</div>
							<p>My final setup was 32 t2.nano instances per region so as to maximize concurrency with maximum number of IPs available at once, while keeping cost low.</p>
							<h3 id="results">Results</h3>
							<p>As soon as I booted up my first batch of 32 t2.nano instances, I noticed an unexpected situation: The manager server is running at constant 100% CPU load. Because Lightsail instances are backed by EC2 T2 series, I knew it wouldn’t sustain for long before having its CPU throttled due to insufficient CPU credits. So I cut off two spider clients, and launched an m5.large instance for the control center.</p>
							<p>Things went on smoothly for a while, and before the job pool depleted, I could gather 500k to 600k results (up to 30 per page). I re-created the pool from scratch a few times, shuffled it each time, and restarted the whole spider swarm. Every time I “refreshed” the database, I could gather another 500k to 600k results, and things went strange in the same mysterious way. The point is, I estimated that there’d be a total of 30M results, so 500k to 600k was really a small portion.</p>
							<p>It’s still delighting that the crawled data from the first few attempts improved the RMSE of our submission from 1.341 to 1.308, though the urgency of a revolutionary refresh also emerged.</p>
							<h2 id="part-3-redesigned-management-architecture-fine-grained-control-more-robust-and-faster">Part 3: Redesigned management architecture, fine-grained control, more robust and faster</h2>
						</section>
						<footer class="page__meta">
							<p class="page__taxonomy">
								<strong><i class="fas fa-fw fa-tags" aria-hidden="true"></i> Tags: </strong>
								<span itemprop="keywords">
									<a href="/tag/aws" class="page__taxonomy-item" rel="tag">aws</a><span class="sep">, </span>
									<a href="/tag/web-scraping" class="page__taxonomy-item" rel="tag">web-scraping</a>
								</span>
							</p>
							<p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-01-01">January 01, 2020</time></p>
						</footer>
						<section class="page__share">
							<a href="https://twitter.com/intent/tweet?text=High-performance+mass+web+crawling+on+AWS%20https%3A%2F%2Fibugone.com%2Fblog%2F2019%2F12%2Fmass-crawl-douban-with-aws%2F" class="btn btn--twitter" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Twitter"><i class="fab fa-fw fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>
							<a href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fibugone.com%2Fblog%2F2019%2F12%2Fmass-crawl-douban-with-aws%2F" class="btn btn--facebook" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on Facebook"><i class="fab fa-fw fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>
							<a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A%2F%2Fibugone.com%2Fblog%2F2019%2F12%2Fmass-crawl-douban-with-aws%2F" class="btn btn--linkedin" onclick="window.open(this.href, 'window', 'left=20,top=20,width=500,height=500,toolbar=1,resizable=0'); return false;" title="Share on LinkedIn"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
						</section>
						<nav class="pagination">
							<a href="/blog/2019/12/manage-servers-with-ssh-ca/" class="pagination--pager" title="Managing servers with OpenSSH Certificate Authority
">Previous</a>
							<a href="#" class="pagination--pager disabled">Next</a>
						</nav>
					</div>
					<div class="page__comments">
						<h4 class="page__comments-title">Comments</h4>
						<section id="disqus_thread"></section>
					</div>
				</article>
				<div class="page__related">
					<h4 class="page__related-title">You May Also Enjoy</h4>
					<div class="grid__wrapper">
						<div class="grid__item">
							<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
								<h2 class="archive__item-title" itemprop="headline">
									<a href="/blog/2019/12/manage-servers-with-ssh-ca/" rel="permalink">Managing servers with OpenSSH Certificate Authority
									</a>
								</h2>
								<p class="page__meta">
									<span style="margin-right: 1em;">
										<i class="far fa-calendar-alt" aria-hidden="true"></i> December 23, 2019
									</span>
									<i class="far fa-clock" aria-hidden="true"></i>
									6 minute read
								</p>
								<p class="archive__item-excerpt" itemprop="description">Since the addition of the website server for an external corporation, I now have 5 Linux servers to manage on my own. I also have 4 terminal devices that I u...</p>
							</article>
						</div>
						<div class="grid__item">
							<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
								<h2 class="archive__item-title" itemprop="headline">
									<a href="/blog/2019/11/change-nvidia-account-email/" rel="permalink">How to change email of your Nvidia account
									</a>
								</h2>
								<p class="page__meta">
									<span style="margin-right: 1em;">
										<i class="far fa-calendar-alt" aria-hidden="true"></i> November 22, 2019
									</span>
									<i class="far fa-clock" aria-hidden="true"></i>
									1 minute read
								</p>
								<p class="archive__item-excerpt" itemprop="description">I recently retired a few old email addresses, and am currently going in a row to change email for accounts associated with those emails. Everything else went...</p>
							</article>
						</div>
						<div class="grid__item">
							<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
								<h2 class="archive__item-title" itemprop="headline">
									<a href="/blog/2019/11/optimize-github-pages-with-cloudflare/" rel="permalink">Make your GitHub Pages website faster with Cloudflare
									</a>
								</h2>
								<p class="page__meta">
									<span style="margin-right: 1em;">
										<i class="far fa-calendar-alt" aria-hidden="true"></i> November 11, 2019
									</span>
									<i class="far fa-clock" aria-hidden="true"></i>
									4 minute read
								</p>
								<p class="archive__item-excerpt" itemprop="description">This September I employed Cloudflare to optimize my website (https://ibugone.com) in various aspects. It turned out to be a brilliant move and Cloudflare has...</p>
							</article>
						</div>
						<div class="grid__item">
							<article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
								<h2 class="archive__item-title" itemprop="headline">
									<a href="/blog/2019/09/convert-dfa-to-regex/" rel="permalink">Converting DFA to Regular Expression
									</a>
								</h2>
								<p class="page__meta">
									<span style="margin-right: 1em;">
										<i class="far fa-calendar-alt" aria-hidden="true"></i> September 25, 2019
									</span>
									<i class="far fa-clock" aria-hidden="true"></i>
									1 minute read
								</p>
								<p class="archive__item-excerpt" itemprop="description">This post originated from Lab 1 of course Compilers: Principles that I’m currently taking, in which we were required to write a flex program to parse a subse...</p>
							</article>
						</div>
					</div>
				</div>
			</div>
		</div>
		<div class="search-content">
			<div class="search-content__inner-wrap">
				<div class="search-searchbar"></div>
				<div class="search-hits"></div>
			</div>
		</div>
		<div id="footer" class="page__footer">
			<footer>
				<!-- start custom footer snippets -->
				<!-- end custom footer snippets -->
				<div class="page__footer-follow">
					<ul class="social-icons">
						<li><a href="https://github.com/iBug" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
						<li><a href="https://stackoverflow.com/users/5958455/ibug" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-stack-overflow" aria-hidden="true"></i> Stack Overflow</a></li>
						<li><a href="/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
					</ul>
				</div>
				<div class="page__footer-copyright">
					&copy; 2020 iBug. Powered by <a href="https://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.
					<br>
					Except otherwise noted, content on this site is licensed under the <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0 License</a>.
					<br>
					<a href="/privacy-policy">Privacy Policy</a> | <a href="/sitemap.xml">Sitemap (XML)</a>
					<br>
					Site version <a href="/status" style="font-family: monospace;">563a2e2</a>
				</div>
			</footer>
		</div>
		<script src="/assets/js/main.min.js"></script>
		<script src="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/js/all.min.js" async defer type="text/javascript"></script>
		<!-- Including InstantSearch.js library and styling -->
		<script src="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.js"></script>
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch.min.css">
		<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/instantsearch.js@2.3.3/dist/instantsearch-theme-algolia.min.css">
		<script>
			// Instanciating InstantSearch.js with Algolia credentials
			const search = instantsearch({
			  appId: '14DZKASAEJ',
			  apiKey: 'a0d8cb9da2d6ad0d17dcd40c58c72a56',
			  indexName: 'iBug_website',
			  searchParameters: {
			    restrictSearchableAttributes: [
			      'title',
			      'content'
			    ]
			  }
			});
			
			const hitTemplate = function(hit) {
			  const url = hit.url;
			  const title = hit._highlightResult.title.value;
			  const content = hit._highlightResult.html.value;
			
			  return `
			    <div class="list__item">
			      <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
			        <h2 class="archive__item-title" itemprop="headline"><a href="${url}">${title}</a></h2>
			        <div class="archive__item-excerpt" itemprop="description">${content}</div>
			      </article>
			    </div>
			  `;
			}
			
			// Adding searchbar and results widgets
			search.addWidget(
			  instantsearch.widgets.searchBox({
			    container: '.search-searchbar',
			    poweredBy: true,
			    placeholder: 'Enter your search term...'
			  })
			);
			search.addWidget(
			  instantsearch.widgets.hits({
			    container: '.search-hits',
			    templates: {
			      item: hitTemplate
			    }
			  })
			);
			
			// Starting the search
			search.start();
		</script>
		<script>
			var _gaq = _gaq || [];
			_gaq.push(['_setAccount', 'UA-115907213-1']);
			
			_gaq.push(['_trackPageview']);
			
			(function() {
			  var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
			  ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
			  var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
			})();
		</script>
		<script>
			var disqus_config = function () {
			  this.page.url = "https://ibugone.com/blog/2019/12/mass-crawl-douban-with-aws/";  // Replace PAGE_URL with your page's canonical URL variable
			  this.page.identifier = "/blog/2019/12/mass-crawl-douban-with-aws"; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
			};
			(function() { // DON'T EDIT BELOW THIS LINE
			  var d = document, s = d.createElement('script');
			  s.src = 'https://ibugone.disqus.com/embed.js';
			  s.setAttribute('data-timestamp', +new Date());
			  (d.head || d.body).appendChild(s);
			})();
		</script>
		<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
	</body>
</html>